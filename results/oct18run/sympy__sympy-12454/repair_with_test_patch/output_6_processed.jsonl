{"model_name_or_path": "agentless", "instance_id": "sympy__sympy-12454", "model_patch": "diff --git a/sympy/matrices/matrices.py b/sympy/matrices/matrices.py\nindex f1dbb52..3811aee 100644\n--- a/sympy/matrices/matrices.py\n+++ b/sympy/matrices/matrices.py\n@@ -1112,7 +1112,7 @@ class MatrixProperties(MatrixRequired):\n         \"\"\"\n         return all(self[i, j].is_zero\n                    for i in range(1, self.rows)\n-                   for j in range(i))\n+                   for j in range(min(i, self.cols)))\n \n     @property\n     def is_zero(self):\n", "raw_model_patch": "diff --git a/sympy/matrices/matrices.py b/sympy/matrices/matrices.py\nindex f1dbb52..3811aee 100644\n--- a/sympy/matrices/matrices.py\n+++ b/sympy/matrices/matrices.py\n@@ -1112,7 +1112,7 @@ class MatrixProperties(MatrixRequired):\n         \"\"\"\n         return all(self[i, j].is_zero\n                    for i in range(1, self.rows)\n-                   for j in range(i))\n+                   for j in range(min(i, self.cols)))\n \n     @property\n     def is_zero(self):\n", "original_file_content": "from __future__ import print_function, division\n\nimport collections\nfrom sympy.core.add import Add\nfrom sympy.core.basic import Basic, Atom\nfrom sympy.core.expr import Expr\nfrom sympy.core.function import count_ops\nfrom sympy.core.logic import fuzzy_and\nfrom sympy.core.power import Pow\nfrom sympy.core.symbol import Symbol, Dummy, symbols\nfrom sympy.core.numbers import Integer, ilcm, Float\nfrom sympy.core.singleton import S\nfrom sympy.core.sympify import sympify\nfrom sympy.core.compatibility import is_sequence, default_sort_key, range, \\\n    NotIterable\n\nfrom sympy.polys import PurePoly, roots, cancel, gcd\nfrom sympy.simplify import simplify as _simplify, signsimp, nsimplify\nfrom sympy.utilities.iterables import flatten, numbered_symbols\nfrom sympy.functions.elementary.miscellaneous import sqrt, Max, Min\nfrom sympy.functions import exp, factorial\nfrom sympy.printing import sstr\nfrom sympy.core.compatibility import reduce, as_int, string_types\nfrom sympy.assumptions.refine import refine\nfrom sympy.core.decorators import call_highest_priority\nfrom sympy.core.decorators import deprecated\nfrom sympy.utilities.exceptions import SymPyDeprecationWarning\n\nfrom types import FunctionType\n\n\ndef _iszero(x):\n    \"\"\"Returns True if x is zero.\"\"\"\n    return x.is_zero\n\n\nclass MatrixError(Exception):\n    pass\n\n\nclass ShapeError(ValueError, MatrixError):\n    \"\"\"Wrong matrix shape\"\"\"\n    pass\n\n\nclass NonSquareMatrixError(ShapeError):\n    pass\n\n\nclass DeferredVector(Symbol, NotIterable):\n    \"\"\"A vector whose components are deferred (e.g. for use with lambdify)\n\n    Examples\n    ========\n\n    >>> from sympy import DeferredVector, lambdify\n    >>> X = DeferredVector( 'X' )\n    >>> X\n    X\n    >>> expr = (X[0] + 2, X[2] + 3)\n    >>> func = lambdify( X, expr)\n    >>> func( [1, 2, 3] )\n    (3, 6)\n    \"\"\"\n\n    def __getitem__(self, i):\n        if i == -0:\n            i = 0\n        if i < 0:\n            raise IndexError('DeferredVector index out of range')\n        component_name = '%s[%d]' % (self.name, i)\n        return Symbol(component_name)\n\n    def __str__(self):\n        return sstr(self)\n\n    def __repr__(self):\n        return \"DeferredVector('%s')\" % (self.name)\n\n\nclass MatrixRequired(object):\n    \"\"\"All subclasses of matrix objects must implement the\n    required matrix properties listed here.\"\"\"\n    rows = None\n    cols = None\n    shape = None\n    _simplify = None\n\n    @classmethod\n    def _new(cls, *args, **kwargs):\n        \"\"\"`_new` must, at minimum, be callable as\n        `_new(rows, cols, mat) where mat is a flat list of the\n        elements of the matrix.\"\"\"\n        raise NotImplementedError(\"Subclasses must implement this.\")\n\n    def __eq__(self, other):\n        raise NotImplementedError(\"Subclasses must impliment this.\")\n\n    def __getitem__(self, key):\n        \"\"\"Implementations of __getitem__ should accept ints, in which\n        case the matrix is indexed as a flat list, tuples (i,j) in which\n        case the (i,j) entry is returned, slices, or mixed tuples (a,b)\n        where a and b are any combintion of slices and integers.\"\"\"\n        raise NotImplementedError(\"Subclasses must implement this.\")\n\n    def __len__(self):\n        \"\"\"The total number of entries in the matrix.\"\"\"\n        raise NotImplementedError(\"Subclasses must implement this.\")\n\n\nclass MatrixShaping(MatrixRequired):\n    \"\"\"Provides basic matrix shaping and extracting of submatrices\"\"\"\n\n    def _eval_col_insert(self, pos, other):\n        cols = self.cols\n\n        def entry(i, j):\n            if j < pos:\n                return self[i, j]\n            elif pos <= j < pos + other.cols:\n                return other[i, j - pos]\n            return self[i, j - pos - other.cols]\n\n        return self._new(self.rows, self.cols + other.cols,\n                         lambda i, j: entry(i, j))\n\n    def _eval_col_join(self, other):\n        rows = self.rows\n\n        def entry(i, j):\n            if i < rows:\n                return self[i, j]\n            return other[i - rows, j]\n\n        return classof(self, other)._new(self.rows + other.rows, self.cols,\n                                         lambda i, j: entry(i, j))\n\n    def _eval_extract(self, rowsList, colsList):\n        mat = list(self)\n        cols = self.cols\n        indices = (i * cols + j for i in rowsList for j in colsList)\n        return self._new(len(rowsList), len(colsList),\n                         list(mat[i] for i in indices))\n\n    def _eval_get_diag_blocks(self):\n        sub_blocks = []\n\n        def recurse_sub_blocks(M):\n            i = 1\n            while i <= M.shape[0]:\n                if i == 1:\n                    to_the_right = M[0, i:]\n                    to_the_bottom = M[i:, 0]\n                else:\n                    to_the_right = M[:i, i:]\n                    to_the_bottom = M[i:, :i]\n                if any(to_the_right) or any(to_the_bottom):\n                    i += 1\n                    continue\n                else:\n                    sub_blocks.append(M[:i, :i])\n                    if M.shape == M[:i, :i].shape:\n                        return\n                    else:\n                        recurse_sub_blocks(M[i:, i:])\n                        return\n\n        recurse_sub_blocks(self)\n        return sub_blocks\n\n    def _eval_row_insert(self, pos, other):\n        entries = list(self)\n        insert_pos = pos * self.cols\n        entries[insert_pos:insert_pos] = list(other)\n        return self._new(self.rows + other.rows, self.cols, entries)\n\n    def _eval_row_join(self, other):\n        cols = self.cols\n\n        def entry(i, j):\n            if j < cols:\n                return self[i, j]\n            return other[i, j - cols]\n\n        return classof(self, other)._new(self.rows, self.cols + other.cols,\n                                         lambda i, j: entry(i, j))\n\n    def _eval_tolist(self):\n        return [list(self[i,:]) for i in range(self.rows)]\n\n    def _eval_vec(self):\n        rows = self.rows\n\n        def entry(n, _):\n            # we want to read off the columns first\n            j = n // rows\n            i = n - j * rows\n            return self[i, j]\n\n        return self._new(len(self), 1, entry)\n\n    def col_insert(self, pos, other):\n        \"\"\"Insert one or more columns at the given column position.\n\n        Examples\n        ========\n\n        >>> from sympy import zeros, ones\n        >>> M = zeros(3)\n        >>> V = ones(3, 1)\n        >>> M.col_insert(1, V)\n        Matrix([\n        [0, 1, 0, 0],\n        [0, 1, 0, 0],\n        [0, 1, 0, 0]])\n\n        See Also\n        ========\n\n        col\n        row_insert\n        \"\"\"\n        # Allows you to build a matrix even if it is null matrix\n        if not self:\n            return type(self)(other)\n\n        if pos < 0:\n            pos = self.cols + pos\n        if pos < 0:\n            pos = 0\n        elif pos > self.cols:\n            pos = self.cols\n\n        if self.rows != other.rows:\n            raise ShapeError(\n                \"self and other must have the same number of rows.\")\n\n        return self._eval_col_insert(pos, other)\n\n    def col_join(self, other):\n        \"\"\"Concatenates two matrices along self's last and other's first row.\n\n        Examples\n        ========\n\n        >>> from sympy import zeros, ones\n        >>> M = zeros(3)\n        >>> V = ones(1, 3)\n        >>> M.col_join(V)\n        Matrix([\n        [0, 0, 0],\n        [0, 0, 0],\n        [0, 0, 0],\n        [1, 1, 1]])\n\n        See Also\n        ========\n\n        col\n        row_join\n        \"\"\"\n        from sympy.matrices import MutableMatrix\n        # Allows you to build a matrix even if it is null matrix\n        if not self:\n            return type(self)(other)\n\n        if self.cols != other.cols:\n            raise ShapeError(\n                \"`self` and `other` must have the same number of columns.\")\n        return self._eval_col_join(other)\n\n    def col(self, j):\n        \"\"\"Elementary column selector.\n\n        Examples\n        ========\n\n        >>> from sympy import eye\n        >>> eye(2).col(0)\n        Matrix([\n        [1],\n        [0]])\n\n        See Also\n        ========\n\n        row\n        col_op\n        col_swap\n        col_del\n        col_join\n        col_insert\n        \"\"\"\n        return self[:, j]\n\n    def extract(self, rowsList, colsList):\n        \"\"\"Return a submatrix by specifying a list of rows and columns.\n        Negative indices can be given. All indices must be in the range\n        -n <= i < n where n is the number of rows or columns.\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix\n        >>> m = Matrix(4, 3, range(12))\n        >>> m\n        Matrix([\n        [0,  1,  2],\n        [3,  4,  5],\n        [6,  7,  8],\n        [9, 10, 11]])\n        >>> m.extract([0, 1, 3], [0, 1])\n        Matrix([\n        [0,  1],\n        [3,  4],\n        [9, 10]])\n\n        Rows or columns can be repeated:\n\n        >>> m.extract([0, 0, 1], [-1])\n        Matrix([\n        [2],\n        [2],\n        [5]])\n\n        Every other row can be taken by using range to provide the indices:\n\n        >>> m.extract(range(0, m.rows, 2), [-1])\n        Matrix([\n        [2],\n        [8]])\n\n        RowsList or colsList can also be a list of booleans, in which case\n        the rows or columns corresponding to the True values will be selected:\n\n        >>> m.extract([0, 1, 2, 3], [True, False, True])\n        Matrix([\n        [0,  2],\n        [3,  5],\n        [6,  8],\n        [9, 11]])\n        \"\"\"\n\n        if not is_sequence(rowsList) or not is_sequence(colsList):\n            raise TypeError(\"rowsList and colsList must be iterable\")\n        # ensure rowsList and colsList are lists of integers\n        if rowsList and all(isinstance(i, bool) for i in rowsList):\n            rowsList = [index for index, item in enumerate(rowsList) if item]\n        if colsList and all(isinstance(i, bool) for i in colsList):\n            colsList = [index for index, item in enumerate(colsList) if item]\n\n        # ensure everything is in range\n        rowsList = [a2idx(k, self.rows) for k in rowsList]\n        colsList = [a2idx(k, self.cols) for k in colsList]\n\n        return self._eval_extract(rowsList, colsList)\n\n    def get_diag_blocks(self):\n        \"\"\"Obtains the square sub-matrices on the main diagonal of a square matrix.\n\n        Useful for inverting symbolic matrices or solving systems of\n        linear equations which may be decoupled by having a block diagonal\n        structure.\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix\n        >>> from sympy.abc import x, y, z\n        >>> A = Matrix([[1, 3, 0, 0], [y, z*z, 0, 0], [0, 0, x, 0], [0, 0, 0, 0]])\n        >>> a1, a2, a3 = A.get_diag_blocks()\n        >>> a1\n        Matrix([\n        [1,    3],\n        [y, z**2]])\n        >>> a2\n        Matrix([[x]])\n        >>> a3\n        Matrix([[0]])\n\n        \"\"\"\n        return self._eval_get_diag_blocks()\n\n    def reshape(self, rows, cols):\n        \"\"\"Reshape the matrix. Total number of elements must remain the same.\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix\n        >>> m = Matrix(2, 3, lambda i, j: 1)\n        >>> m\n        Matrix([\n        [1, 1, 1],\n        [1, 1, 1]])\n        >>> m.reshape(1, 6)\n        Matrix([[1, 1, 1, 1, 1, 1]])\n        >>> m.reshape(3, 2)\n        Matrix([\n        [1, 1],\n        [1, 1],\n        [1, 1]])\n\n        \"\"\"\n        if self.rows * self.cols != rows * cols:\n            raise ValueError(\"Invalid reshape parameters %d %d\" % (rows, cols))\n        return self._new(rows, cols, lambda i, j: self[i * cols + j])\n\n    def row_insert(self, pos, other):\n        \"\"\"Insert one or more rows at the given row position.\n\n        Examples\n        ========\n\n        >>> from sympy import zeros, ones\n        >>> M = zeros(3)\n        >>> V = ones(1, 3)\n        >>> M.row_insert(1, V)\n        Matrix([\n        [0, 0, 0],\n        [1, 1, 1],\n        [0, 0, 0],\n        [0, 0, 0]])\n\n        See Also\n        ========\n\n        row\n        col_insert\n        \"\"\"\n        from sympy.matrices import MutableMatrix\n        # Allows you to build a matrix even if it is null matrix\n        if not self:\n            return self._new(other)\n\n        if pos < 0:\n            pos = self.rows + pos\n        if pos < 0:\n            pos = 0\n        elif pos > self.rows:\n            pos = self.rows\n\n        if self.cols != other.cols:\n            raise ShapeError(\n                \"`self` and `other` must have the same number of columns.\")\n\n        return self._eval_row_insert(pos, other)\n\n    def row_join(self, other):\n        \"\"\"Concatenates two matrices along self's last and rhs's first column\n\n        Examples\n        ========\n\n        >>> from sympy import zeros, ones\n        >>> M = zeros(3)\n        >>> V = ones(3, 1)\n        >>> M.row_join(V)\n        Matrix([\n        [0, 0, 0, 1],\n        [0, 0, 0, 1],\n        [0, 0, 0, 1]])\n\n        See Also\n        ========\n\n        row\n        col_join\n        \"\"\"\n        # Allows you to build a matrix even if it is null matrix\n        if not self:\n            return self._new(other)\n\n        if self.rows != other.rows:\n            raise ShapeError(\n                \"`self` and `rhs` must have the same number of rows.\")\n        return self._eval_row_join(other)\n\n    def row(self, i):\n        \"\"\"Elementary row selector.\n\n        Examples\n        ========\n\n        >>> from sympy import eye\n        >>> eye(2).row(0)\n        Matrix([[1, 0]])\n\n        See Also\n        ========\n\n        col\n        row_op\n        row_swap\n        row_del\n        row_join\n        row_insert\n        \"\"\"\n        return self[i, :]\n\n    @property\n    def shape(self):\n        \"\"\"The shape (dimensions) of the matrix as the 2-tuple (rows, cols).\n\n        Examples\n        ========\n\n        >>> from sympy.matrices import zeros\n        >>> M = zeros(2, 3)\n        >>> M.shape\n        (2, 3)\n        >>> M.rows\n        2\n        >>> M.cols\n        3\n        \"\"\"\n        return (self.rows, self.cols)\n\n    def tolist(self):\n        \"\"\"Return the Matrix as a nested Python list.\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix, ones\n        >>> m = Matrix(3, 3, range(9))\n        >>> m\n        Matrix([\n        [0, 1, 2],\n        [3, 4, 5],\n        [6, 7, 8]])\n        >>> m.tolist()\n        [[0, 1, 2], [3, 4, 5], [6, 7, 8]]\n        >>> ones(3, 0).tolist()\n        [[], [], []]\n\n        When there are no rows then it will not be possible to tell how\n        many columns were in the original matrix:\n\n        >>> ones(0, 3).tolist()\n        []\n\n        \"\"\"\n        if not self.rows:\n            return []\n        if not self.cols:\n            return [[] for i in range(self.rows)]\n        return self._eval_tolist()\n\n    def vec(self):\n        \"\"\"Return the Matrix converted into a one column matrix by stacking columns\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix\n        >>> m=Matrix([[1, 3], [2, 4]])\n        >>> m\n        Matrix([\n        [1, 3],\n        [2, 4]])\n        >>> m.vec()\n        Matrix([\n        [1],\n        [2],\n        [3],\n        [4]])\n\n        See Also\n        ========\n\n        vech\n        \"\"\"\n        return self._eval_vec()\n\n\nclass MatrixProperties(MatrixRequired):\n    \"\"\"Provides basic properties of a matrix.\"\"\"\n\n    def _eval_atoms(self, *types):\n        result = set()\n        for i in self:\n            result.update(i.atoms(*types))\n        return result\n\n    def _eval_free_symbols(self):\n        return set().union(*(i.free_symbols for i in self))\n\n    def _eval_has(self, *patterns):\n        return any(a.has(*patterns) for a in self)\n\n    def _eval_is_anti_symmetric(self, simpfunc):\n        if not all(simpfunc(self[i, j] + self[j, i]).is_zero for i in range(self.rows) for j in range(self.cols)):\n            return False\n        return True\n\n    def _eval_is_diagonal(self):\n        for i in range(self.rows):\n            for j in range(self.cols):\n                if i != j and self[i, j]:\n                    return False\n        return True\n\n    def _eval_is_hermetian(self, simpfunc):\n        mat = self._new(self.rows, self.cols, lambda i, j: simpfunc(self[i, j] - self[j, i].conjugate()))\n        return mat.is_zero\n\n    def _eval_is_Identity(self):\n        def dirac(i, j):\n            if i == j:\n                return 1\n            return 0\n\n        return all(self[i, j] == dirac(i, j) for i in range(self.rows) for j in\n                   range(self.cols))\n\n    def _eval_is_lower_hessenberg(self):\n        return all(self[i, j].is_zero\n                   for i in range(self.rows)\n                   for j in range(i + 2, self.cols))\n\n    def _eval_is_lower(self):\n        return all(self[i, j].is_zero\n                   for i in range(self.rows)\n                   for j in range(i + 1, self.cols))\n\n    def _eval_is_symbolic(self):\n        return self.has(Symbol)\n\n    def _eval_is_symmetric(self, simpfunc):\n        mat = self._new(self.rows, self.cols, lambda i, j: simpfunc(self[i, j] - self[j, i]))\n        return mat.is_zero\n\n    def _eval_is_zero(self):\n        if any(i.is_zero == False for i in self):\n            return False\n        if any(i.is_zero == None for i in self):\n            return None\n        return True\n\n    def _eval_is_upper_hessenberg(self):\n        return all(self[i, j].is_zero\n                   for i in range(2, self.rows)\n                   for j in range(i - 1))\n\n    def _eval_values(self):\n        return [i for i in self if not i.is_zero]\n\n    def atoms(self, *types):\n        \"\"\"Returns the atoms that form the current object.\n\n        Examples\n        ========\n\n        >>> from sympy.abc import x, y\n        >>> from sympy.matrices import Matrix\n        >>> Matrix([[x]])\n        Matrix([[x]])\n        >>> _.atoms()\n        {x}\n        \"\"\"\n\n        types = tuple(t if isinstance(t, type) else type(t) for t in types)\n        if not types:\n            types = (Atom,)\n        return self._eval_atoms(*types)\n\n    @property\n    def free_symbols(self):\n        \"\"\"Returns the free symbols within the matrix.\n\n        Examples\n        ========\n\n        >>> from sympy.abc import x\n        >>> from sympy.matrices import Matrix\n        >>> Matrix([[x], [1]]).free_symbols\n        {x}\n        \"\"\"\n        return self._eval_free_symbols()\n\n    def has(self, *patterns):\n        \"\"\"Test whether any subexpression matches any of the patterns.\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix, SparseMatrix, Float\n        >>> from sympy.abc import x, y\n        >>> A = Matrix(((1, x), (0.2, 3)))\n        >>> B = SparseMatrix(((1, x), (0.2, 3)))\n        >>> A.has(x)\n        True\n        >>> A.has(y)\n        False\n        >>> A.has(Float)\n        True\n        >>> B.has(x)\n        True\n        >>> B.has(y)\n        False\n        >>> B.has(Float)\n        True\n        \"\"\"\n        return self._eval_has(*patterns)\n\n    def is_anti_symmetric(self, simplify=True):\n        \"\"\"Check if matrix M is an antisymmetric matrix,\n        that is, M is a square matrix with all M[i, j] == -M[j, i].\n\n        When ``simplify=True`` (default), the sum M[i, j] + M[j, i] is\n        simplified before testing to see if it is zero. By default,\n        the SymPy simplify function is used. To use a custom function\n        set simplify to a function that accepts a single argument which\n        returns a simplified expression. To skip simplification, set\n        simplify to False but note that although this will be faster,\n        it may induce false negatives.\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix, symbols\n        >>> m = Matrix(2, 2, [0, 1, -1, 0])\n        >>> m\n        Matrix([\n        [ 0, 1],\n        [-1, 0]])\n        >>> m.is_anti_symmetric()\n        True\n        >>> x, y = symbols('x y')\n        >>> m = Matrix(2, 3, [0, 0, x, -y, 0, 0])\n        >>> m\n        Matrix([\n        [ 0, 0, x],\n        [-y, 0, 0]])\n        >>> m.is_anti_symmetric()\n        False\n\n        >>> from sympy.abc import x, y\n        >>> m = Matrix(3, 3, [0, x**2 + 2*x + 1, y,\n        ...                   -(x + 1)**2 , 0, x*y,\n        ...                   -y, -x*y, 0])\n\n        Simplification of matrix elements is done by default so even\n        though two elements which should be equal and opposite wouldn't\n        pass an equality test, the matrix is still reported as\n        anti-symmetric:\n\n        >>> m[0, 1] == -m[1, 0]\n        False\n        >>> m.is_anti_symmetric()\n        True\n\n        If 'simplify=False' is used for the case when a Matrix is already\n        simplified, this will speed things up. Here, we see that without\n        simplification the matrix does not appear anti-symmetric:\n\n        >>> m.is_anti_symmetric(simplify=False)\n        False\n\n        But if the matrix were already expanded, then it would appear\n        anti-symmetric and simplification in the is_anti_symmetric routine\n        is not needed:\n\n        >>> m = m.expand()\n        >>> m.is_anti_symmetric(simplify=False)\n        True\n        \"\"\"\n        # accept custom simplification\n        simpfunc = simplify\n        if not isinstance(simplify, FunctionType):\n            simpfunc = _simplify if simplify else lambda x: x\n\n        if not self.is_square:\n            return False\n        return self._eval_is_anti_symmetric(simpfunc)\n\n    def is_diagonal(self):\n        \"\"\"Check if matrix is diagonal,\n        that is matrix in which the entries outside the main diagonal are all zero.\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix, diag\n        >>> m = Matrix(2, 2, [1, 0, 0, 2])\n        >>> m\n        Matrix([\n        [1, 0],\n        [0, 2]])\n        >>> m.is_diagonal()\n        True\n\n        >>> m = Matrix(2, 2, [1, 1, 0, 2])\n        >>> m\n        Matrix([\n        [1, 1],\n        [0, 2]])\n        >>> m.is_diagonal()\n        False\n\n        >>> m = diag(1, 2, 3)\n        >>> m\n        Matrix([\n        [1, 0, 0],\n        [0, 2, 0],\n        [0, 0, 3]])\n        >>> m.is_diagonal()\n        True\n\n        See Also\n        ========\n\n        is_lower\n        is_upper\n        is_diagonalizable\n        diagonalize\n        \"\"\"\n        return self._eval_is_diagonal()\n\n    @property\n    def is_hermitian(self, simplify=True):\n        \"\"\"Checks if the matrix is Hermitian.\n\n        In a Hermitian matrix element i,j is the complex conjugate of\n        element j,i.\n\n        Examples\n        ========\n\n        >>> from sympy.matrices import Matrix\n        >>> from sympy import I\n        >>> from sympy.abc import x\n        >>> a = Matrix([[1, I], [-I, 1]])\n        >>> a\n        Matrix([\n        [ 1, I],\n        [-I, 1]])\n        >>> a.is_hermitian\n        True\n        >>> a[0, 0] = 2*I\n        >>> a.is_hermitian\n        False\n        >>> a[0, 0] = x\n        >>> a.is_hermitian\n        >>> a[0, 1] = a[1, 0]*I\n        >>> a.is_hermitian\n        False\n        \"\"\"\n        if not self.is_square:\n            return False\n\n        simpfunc = simplify\n        if not isinstance(simplify, FunctionType):\n            simpfunc = _simplify if simplify else lambda x: x\n\n        return self._eval_is_hermetian(simpfunc)\n\n    @property\n    def is_Identity(self):\n        if not self.is_square:\n            return False\n        return self._eval_is_Identity()\n\n    @property\n    def is_lower_hessenberg(self):\n        r\"\"\"Checks if the matrix is in the lower-Hessenberg form.\n\n        The lower hessenberg matrix has zero entries\n        above the first superdiagonal.\n\n        Examples\n        ========\n\n        >>> from sympy.matrices import Matrix\n        >>> a = Matrix([[1, 2, 0, 0], [5, 2, 3, 0], [3, 4, 3, 7], [5, 6, 1, 1]])\n        >>> a\n        Matrix([\n        [1, 2, 0, 0],\n        [5, 2, 3, 0],\n        [3, 4, 3, 7],\n        [5, 6, 1, 1]])\n        >>> a.is_lower_hessenberg\n        True\n\n        See Also\n        ========\n\n        is_upper_hessenberg\n        is_lower\n        \"\"\"\n        return self._eval_is_lower_hessenberg()\n\n    @property\n    def is_lower(self):\n        \"\"\"Check if matrix is a lower triangular matrix. True can be returned\n        even if the matrix is not square.\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix\n        >>> m = Matrix(2, 2, [1, 0, 0, 1])\n        >>> m\n        Matrix([\n        [1, 0],\n        [0, 1]])\n        >>> m.is_lower\n        True\n\n        >>> m = Matrix(4, 3, [0, 0, 0, 2, 0, 0, 1, 4 , 0, 6, 6, 5])\n        >>> m\n        Matrix([\n        [0, 0, 0],\n        [2, 0, 0],\n        [1, 4, 0],\n        [6, 6, 5]])\n        >>> m.is_lower\n        True\n\n        >>> from sympy.abc import x, y\n        >>> m = Matrix(2, 2, [x**2 + y, y**2 + x, 0, x + y])\n        >>> m\n        Matrix([\n        [x**2 + y, x + y**2],\n        [       0,    x + y]])\n        >>> m.is_lower\n        False\n\n        See Also\n        ========\n\n        is_upper\n        is_diagonal\n        is_lower_hessenberg\n        \"\"\"\n        return self._eval_is_lower()\n\n    @property\n    def is_square(self):\n        \"\"\"Checks if a matrix is square.\n\n        A matrix is square if the number of rows equals the number of columns.\n        The empty matrix is square by definition, since the number of rows and\n        the number of columns are both zero.\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix\n        >>> a = Matrix([[1, 2, 3], [4, 5, 6]])\n        >>> b = Matrix([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n        >>> c = Matrix([])\n        >>> a.is_square\n        False\n        >>> b.is_square\n        True\n        >>> c.is_square\n        True\n        \"\"\"\n        return self.rows == self.cols\n\n    def is_symbolic(self):\n        \"\"\"Checks if any elements contain Symbols.\n\n        Examples\n        ========\n\n        >>> from sympy.matrices import Matrix\n        >>> from sympy.abc import x, y\n        >>> M = Matrix([[x, y], [1, 0]])\n        >>> M.is_symbolic()\n        True\n\n        \"\"\"\n        return self._eval_is_symbolic()\n\n    def is_symmetric(self, simplify=True):\n        \"\"\"Check if matrix is symmetric matrix,\n        that is square matrix and is equal to its transpose.\n\n        By default, simplifications occur before testing symmetry.\n        They can be skipped using 'simplify=False'; while speeding things a bit,\n        this may however induce false negatives.\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix\n        >>> m = Matrix(2, 2, [0, 1, 1, 2])\n        >>> m\n        Matrix([\n        [0, 1],\n        [1, 2]])\n        >>> m.is_symmetric()\n        True\n\n        >>> m = Matrix(2, 2, [0, 1, 2, 0])\n        >>> m\n        Matrix([\n        [0, 1],\n        [2, 0]])\n        >>> m.is_symmetric()\n        False\n\n        >>> m = Matrix(2, 3, [0, 0, 0, 0, 0, 0])\n        >>> m\n        Matrix([\n        [0, 0, 0],\n        [0, 0, 0]])\n        >>> m.is_symmetric()\n        False\n\n        >>> from sympy.abc import x, y\n        >>> m = Matrix(3, 3, [1, x**2 + 2*x + 1, y, (x + 1)**2 , 2, 0, y, 0, 3])\n        >>> m\n        Matrix([\n        [         1, x**2 + 2*x + 1, y],\n        [(x + 1)**2,              2, 0],\n        [         y,              0, 3]])\n        >>> m.is_symmetric()\n        True\n\n        If the matrix is already simplified, you may speed-up is_symmetric()\n        test by using 'simplify=False'.\n\n        >>> bool(m.is_symmetric(simplify=False))\n        False\n        >>> m1 = m.expand()\n        >>> m1.is_symmetric(simplify=False)\n        True\n        \"\"\"\n        simpfunc = simplify\n        if not isinstance(simplify, FunctionType):\n            simpfunc = _simplify if simplify else lambda x: x\n\n        if not self.is_square:\n            return False\n\n        return self._eval_is_symmetric(simpfunc)\n\n    @property\n    def is_upper_hessenberg(self):\n        \"\"\"Checks if the matrix is the upper-Hessenberg form.\n\n        The upper hessenberg matrix has zero entries\n        below the first subdiagonal.\n\n        Examples\n        ========\n\n        >>> from sympy.matrices import Matrix\n        >>> a = Matrix([[1, 4, 2, 3], [3, 4, 1, 7], [0, 2, 3, 4], [0, 0, 1, 3]])\n        >>> a\n        Matrix([\n        [1, 4, 2, 3],\n        [3, 4, 1, 7],\n        [0, 2, 3, 4],\n        [0, 0, 1, 3]])\n        >>> a.is_upper_hessenberg\n        True\n\n        See Also\n        ========\n\n        is_lower_hessenberg\n        is_upper\n        \"\"\"\n        return self._eval_is_upper_hessenberg()\n\n    @property\n    def is_upper(self):\n        \"\"\"Check if matrix is an upper triangular matrix. True can be returned\n        even if the matrix is not square.\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix\n        >>> m = Matrix(2, 2, [1, 0, 0, 1])\n        >>> m\n        Matrix([\n        [1, 0],\n        [0, 1]])\n        >>> m.is_upper\n        True\n\n        >>> m = Matrix(4, 3, [5, 1, 9, 0, 4 , 6, 0, 0, 5, 0, 0, 0])\n        >>> m\n        Matrix([\n        [5, 1, 9],\n        [0, 4, 6],\n        [0, 0, 5],\n        [0, 0, 0]])\n        >>> m.is_upper\n        True\n\n        >>> m = Matrix(2, 3, [4, 2, 5, 6, 1, 1])\n        >>> m\n        Matrix([\n        [4, 2, 5],\n        [6, 1, 1]])\n        >>> m.is_upper\n        False\n\n        See Also\n        ========\n\n        is_lower\n        is_diagonal\n        is_upper_hessenberg\n        \"\"\"\n        return all(self[i, j].is_zero\n                   for i in range(1, self.rows)\n                   for j in range(i))\n\n    @property\n    def is_zero(self):\n        \"\"\"Checks if a matrix is a zero matrix.\n\n        A matrix is zero if every element is zero.  A matrix need not be square\n        to be considered zero.  The empty matrix is zero by the principle of\n        vacuous truth.  For a matrix that may or may not be zero (e.g.\n        contains a symbol), this will be None\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix, zeros\n        >>> from sympy.abc import x\n        >>> a = Matrix([[0, 0], [0, 0]])\n        >>> b = zeros(3, 4)\n        >>> c = Matrix([[0, 1], [0, 0]])\n        >>> d = Matrix([])\n        >>> e = Matrix([[x, 0], [0, 0]])\n        >>> a.is_zero\n        True\n        >>> b.is_zero\n        True\n        >>> c.is_zero\n        False\n        >>> d.is_zero\n        True\n        >>> e.is_zero\n        \"\"\"\n        return self._eval_is_zero()\n\n    def values(self):\n        \"\"\"Return non-zero values of self.\"\"\"\n        return self._eval_values()\n\n\nclass MatrixOperations(MatrixRequired):\n    \"\"\"Provides basic matrix shape and elementwise\n    operations.  Should not be instantiated directly.\"\"\"\n\n    def _eval_adjoint(self):\n        return self.transpose().conjugate()\n\n    def _eval_applyfunc(self, f):\n        out = self._new(self.rows, self.cols, [f(x) for x in self])\n        return out\n\n    def _eval_as_real_imag(self):\n        from sympy.functions.elementary.complexes import re, im\n\n        return (self.applyfunc(re), self.applyfunc(im))\n\n    def _eval_conjugate(self):\n        return self.applyfunc(lambda x: x.conjugate())\n\n    def _eval_trace(self):\n        return sum(self[i, i] for i in range(self.rows))\n\n    def _eval_transpose(self):\n        return self._new(self.cols, self.rows, lambda i, j: self[j, i])\n\n    def adjoint(self):\n        \"\"\"Conjugate transpose or Hermitian conjugation.\"\"\"\n        return self._eval_adjoint()\n\n    def applyfunc(self, f):\n        \"\"\"Apply a function to each element of the matrix.\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix\n        >>> m = Matrix(2, 2, lambda i, j: i*2+j)\n        >>> m\n        Matrix([\n        [0, 1],\n        [2, 3]])\n        >>> m.applyfunc(lambda i: 2*i)\n        Matrix([\n        [0, 2],\n        [4, 6]])\n\n        \"\"\"\n        if not callable(f):\n            raise TypeError(\"`f` must be callable.\")\n\n        return self._eval_applyfunc(f)\n\n    def as_real_imag(self):\n        \"\"\"Returns a tuple containing the (real, imaginary) part of matrix.\"\"\"\n        return self._eval_as_real_imag()\n\n    def conjugate(self):\n        \"\"\"Return the by-element conjugation.\n\n        Examples\n        ========\n\n        >>> from sympy.matrices import SparseMatrix\n        >>> from sympy import I\n        >>> a = SparseMatrix(((1, 2 + I), (3, 4), (I, -I)))\n        >>> a\n        Matrix([\n        [1, 2 + I],\n        [3,     4],\n        [I,    -I]])\n        >>> a.C\n        Matrix([\n        [ 1, 2 - I],\n        [ 3,     4],\n        [-I,     I]])\n\n        See Also\n        ========\n\n        transpose: Matrix transposition\n        H: Hermite conjugation\n        D: Dirac conjugation\n        \"\"\"\n        return self._eval_conjugate()\n\n    def doit(self, **kwargs):\n        return self.applyfunc(lambda x: x.doit())\n\n    def evalf(self, prec=None, **options):\n        \"\"\"Apply evalf() to each element of self.\"\"\"\n        return self.applyfunc(lambda i: i.evalf(prec, **options))\n\n    def expand(self, deep=True, modulus=None, power_base=True, power_exp=True,\n               mul=True, log=True, multinomial=True, basic=True, **hints):\n        \"\"\"Apply core.function.expand to each entry of the matrix.\n\n        Examples\n        ========\n\n        >>> from sympy.abc import x\n        >>> from sympy.matrices import Matrix\n        >>> Matrix(1, 1, [x*(x+1)])\n        Matrix([[x*(x + 1)]])\n        >>> _.expand()\n        Matrix([[x**2 + x]])\n\n        \"\"\"\n        return self.applyfunc(lambda x: x.expand(\n            deep, modulus, power_base, power_exp, mul, log, multinomial, basic,\n            **hints))\n\n    @property\n    def H(self):\n        \"\"\"Return Hermite conjugate.\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix, I\n        >>> m = Matrix((0, 1 + I, 2, 3))\n        >>> m\n        Matrix([\n        [    0],\n        [1 + I],\n        [    2],\n        [    3]])\n        >>> m.H\n        Matrix([[0, 1 - I, 2, 3]])\n\n        See Also\n        ========\n\n        conjugate: By-element conjugation\n        D: Dirac conjugation\n        \"\"\"\n        return self.T.C\n\n    def refine(self, assumptions=True):\n        \"\"\"Apply refine to each element of the matrix.\n\n        Examples\n        ========\n\n        >>> from sympy import Symbol, Matrix, Abs, sqrt, Q\n        >>> x = Symbol('x')\n        >>> Matrix([[Abs(x)**2, sqrt(x**2)],[sqrt(x**2), Abs(x)**2]])\n        Matrix([\n        [ Abs(x)**2, sqrt(x**2)],\n        [sqrt(x**2),  Abs(x)**2]])\n        >>> _.refine(Q.real(x))\n        Matrix([\n        [  x**2, Abs(x)],\n        [Abs(x),   x**2]])\n\n        \"\"\"\n        return self.applyfunc(lambda x: refine(x, assumptions))\n\n    def replace(self, F, G, map=False):\n        \"\"\"Replaces Function F in Matrix entries with Function G.\n\n        Examples\n        ========\n\n        >>> from sympy import symbols, Function, Matrix\n        >>> F, G = symbols('F, G', cls=Function)\n        >>> M = Matrix(2, 2, lambda i, j: F(i+j)) ; M\n        Matrix([\n        [F(0), F(1)],\n        [F(1), F(2)]])\n        >>> N = M.replace(F,G)\n        >>> N\n        Matrix([\n        [G(0), G(1)],\n        [G(1), G(2)]])\n        \"\"\"\n        return self.applyfunc(lambda x: x.replace(F, G, map))\n\n    def simplify(self, ratio=1.7, measure=count_ops):\n        \"\"\"Apply simplify to each element of the matrix.\n\n        Examples\n        ========\n\n        >>> from sympy.abc import x, y\n        >>> from sympy import sin, cos\n        >>> from sympy.matrices import SparseMatrix\n        >>> SparseMatrix(1, 1, [x*sin(y)**2 + x*cos(y)**2])\n        Matrix([[x*sin(y)**2 + x*cos(y)**2]])\n        >>> _.simplify()\n        Matrix([[x]])\n        \"\"\"\n        return self.applyfunc(lambda x: x.simplify(ratio, measure))\n\n    def subs(self, *args, **kwargs):  # should mirror core.basic.subs\n        \"\"\"Return a new matrix with subs applied to each entry.\n\n        Examples\n        ========\n\n        >>> from sympy.abc import x, y\n        >>> from sympy.matrices import SparseMatrix, Matrix\n        >>> SparseMatrix(1, 1, [x])\n        Matrix([[x]])\n        >>> _.subs(x, y)\n        Matrix([[y]])\n        >>> Matrix(_).subs(y, x)\n        Matrix([[x]])\n        \"\"\"\n        return self.applyfunc(lambda x: x.subs(*args, **kwargs))\n\n    def trace(self):\n        \"\"\"\n        Returns the trace of a square matrix i.e. the sum of the\n        diagonal elements.\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix\n        >>> A = Matrix(2, 2, [1, 2, 3, 4])\n        >>> A.trace()\n        5\n\n        \"\"\"\n        if not self.rows == self.cols:\n            raise NonSquareMatrixError()\n        return self._eval_trace()\n\n    def transpose(self):\n        \"\"\"\n        Returns the transpose of the matrix.\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix\n        >>> A = Matrix(2, 2, [1, 2, 3, 4])\n        >>> A.transpose()\n        Matrix([\n        [1, 3],\n        [2, 4]])\n\n        >>> from sympy import Matrix, I\n        >>> m=Matrix(((1, 2+I), (3, 4)))\n        >>> m\n        Matrix([\n        [1, 2 + I],\n        [3,     4]])\n        >>> m.transpose()\n        Matrix([\n        [    1, 3],\n        [2 + I, 4]])\n        >>> m.T == m.transpose()\n        True\n\n        See Also\n        ========\n\n        conjugate: By-element conjugation\n\n        \"\"\"\n        return self._eval_transpose()\n\n    T = property(transpose, None, None, \"Matrix transposition.\")\n\n    C = property(conjugate, None, None, \"By-element conjugation.\")\n\n    n = evalf\n\n    def xreplace(self, rule):  # should mirror core.basic.xreplace\n        \"\"\"Return a new matrix with xreplace applied to each entry.\n\n        Examples\n        ========\n\n        >>> from sympy.abc import x, y\n        >>> from sympy.matrices import SparseMatrix, Matrix\n        >>> SparseMatrix(1, 1, [x])\n        Matrix([[x]])\n        >>> _.xreplace({x: y})\n        Matrix([[y]])\n        >>> Matrix(_).xreplace({y: x})\n        Matrix([[x]])\n        \"\"\"\n        return self.applyfunc(lambda x: x.xreplace(rule))\n\n    _eval_simplify = simplify\n\n\nclass MatrixArithmetic(MatrixRequired):\n    \"\"\"Provides basic matrix arithmetic operations.\n    Should not be instantiated directly.\"\"\"\n\n    _op_priority = 10.01\n\n    def _eval_add(self, other):\n        return self._new(self.rows, self.cols,\n                         lambda i, j: self[i, j] + other[i, j])\n\n    def _eval_matrix_mul(self, other):\n        def entry(i, j):\n            try:\n                return sum(self[i,k]*other[k,j] for k in range(self.cols))\n            except TypeError:\n                # Block matrices don't work with `sum` or `Add` (ISSUE #11599)\n                # They don't work with `sum` because `sum` tries to add `0`\n                # initially, and for a matrix, that is a mix of a scalar and\n                # a matrix, which raises a TypeError. Fall back to a\n                # block-matrix-safe way to multiply if the `sum` fails.\n                ret = self[i, 0]*other[0, j]\n                for k in range(1, self.cols):\n                    ret += self[i, k]*other[k, j]\n                return ret\n\n        return self._new(self.rows, other.cols, entry)\n\n    def _eval_matrix_mul_elementwise(self, other):\n        return self._new(self.rows, self.cols, lambda i, j: self[i,j]*other[i,j])\n\n    def _eval_matrix_rmul(self, other):\n        def entry(i, j):\n            return sum(other[i,k]*self[k,j] for k in range(other.cols))\n        return self._new(other.rows, self.cols, entry)\n\n    def _eval_pow_by_recursion(self, num):\n        if num == 1:\n            return self\n        if num % 2 == 1:\n            return self * self._eval_pow_by_recursion(num - 1)\n        ret = self._eval_pow_by_recursion(num // 2)\n        return ret * ret\n\n    def _eval_scalar_mul(self, other):\n        return self._new(self.rows, self.cols, lambda i, j: self[i,j]*other)\n\n    def _eval_scalar_rmul(self, other):\n        return self._new(self.rows, self.cols, lambda i, j: other*self[i,j])\n\n    # python arithmetic functions\n    @call_highest_priority('__radd__')\n    def __add__(self, other):\n        \"\"\"Return self + other, raising ShapeError if shapes don't match.\"\"\"\n        other = _matrixify(other)\n        # matrix-like objects can have shapes.  This is\n        # our first sanity check.\n        if hasattr(other, 'shape'):\n            if self.shape != other.shape:\n                raise ShapeError(\"Matrix size mismatch: %s + %s\" % (\n                    self.shape, other.shape))\n\n        # honest sympy matrices defer to their class's routine\n        if getattr(other, 'is_Matrix', False):\n            # call the highest-priority class's _eval_add\n            a, b = self, other\n            if a.__class__ != classof(a, b):\n                b, a = a, b\n            return a._eval_add(b)\n        # Matrix-like objects can be passed to CommonMatrix routines directly.\n        if getattr(other, 'is_MatrixLike', False):\n            return MatrixArithmetic._eval_add(self, other)\n\n        raise TypeError('cannot add %s and %s' % type(self), type(other))\n\n    @call_highest_priority('__rdiv__')\n    def __div__(self, other):\n        return self * (S.One / other)\n\n    @call_highest_priority('__rmatmul__')\n    def __matmul__(self, other):\n        return self.__mul__(other)\n\n    @call_highest_priority('__rmul__')\n    def __mul__(self, other):\n        \"\"\"Return self*other where other is either a scalar or a matrix\n        of compatible dimensions.\n\n        Examples\n        ========\n\n        >>> from sympy.matrices import Matrix\n        >>> A = Matrix([[1, 2, 3], [4, 5, 6]])\n        >>> 2*A == A*2 == Matrix([[2, 4, 6], [8, 10, 12]])\n        True\n        >>> B = Matrix([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n        >>> A*B\n        Matrix([\n        [30, 36, 42],\n        [66, 81, 96]])\n        >>> B*A\n        Traceback (most recent call last):\n        ...\n        ShapeError: Matrices size mismatch.\n        >>>\n\n        See Also\n        ========\n\n        matrix_multiply_elementwise\n        \"\"\"\n        other = _matrixify(other)\n        # matrix-like objects can have shapes.  This is\n        # our first sanity check.\n        if hasattr(other, 'shape') and len(other.shape) == 2:\n            if self.shape[1] != other.shape[0]:\n                raise ShapeError(\"Matrix size mismatch: %s * %s.\" % (\n                    self.shape, other.shape))\n\n        # honest sympy matrices defer to their class's routine\n        if getattr(other, 'is_Matrix', False):\n            return self._eval_matrix_mul(other)\n        # Matrix-like objects can be passed to CommonMatrix routines directly.\n        if getattr(other, 'is_MatrixLike', False):\n            return MatrixArithmetic._eval_matrix_mul(self, other)\n\n        try:\n            return self._eval_scalar_mul(other)\n        except TypeError:\n            pass\n\n        raise TypeError('Cannot multiply %s and %s' % type(self), type(other))\n\n    def __neg__(self):\n        return self._eval_scalar_mul(-1)\n\n    @call_highest_priority('__rpow__')\n    def __pow__(self, num):\n        if not self.rows == self.cols:\n            raise NonSquareMatrixError()\n        try:\n            a = self\n            num = sympify(num)\n            if num.is_Number and num % 1 == 0:\n                if a.rows == 1:\n                    return a._new([[a[0]**num]])\n                if num == 0:\n                    return self._new(self.rows, self.cols, lambda i, j: int(i == j))\n                if num < 0:\n                    num = -num\n                    a = a.inv()\n                # When certain conditions are met,\n                # Jordan block algorithm is faster than\n                # computation by recursion.\n                elif a.rows == 2 and num > 100000:\n                    try:\n                        return a._matrix_pow_by_jordan_blocks(num)\n                    except AttributeError:\n                        pass\n                return a._eval_pow_by_recursion(num)\n            elif isinstance(num, (Expr, float)):\n                return a._matrix_pow_by_jordan_blocks(num)\n            else:\n                raise TypeError(\n                    \"Only SymPy expressions or integers are supported as exponent for matrices\")\n        except AttributeError:\n            raise TypeError(\"Don't know how to raise {} to {}\".format(self.__class__, num))\n\n    @call_highest_priority('__add__')\n    def __radd__(self, other):\n        return self + other\n\n    @call_highest_priority('__matmul__')\n    def __rmatmul__(self, other):\n        return self.__rmul__(other)\n\n    @call_highest_priority('__mul__')\n    def __rmul__(self, other):\n        other = _matrixify(other)\n        # matrix-like objects can have shapes.  This is\n        # our first sanity check.\n        if hasattr(other, 'shape') and len(other.shape) == 2:\n            if self.shape[0] != other.shape[1]:\n                raise ShapeError(\"Matrix size mismatch.\")\n\n        # honest sympy matrices defer to their class's routine\n        if getattr(other, 'is_Matrix', False):\n            return other._new(other.as_mutable() * self)\n        # Matrix-like objects can be passed to CommonMatrix routines directly.\n        if getattr(other, 'is_MatrixLike', False):\n            return MatrixArithmetic._eval_matrix_rmul(self, other)\n\n        try:\n            return self._eval_scalar_rmul(other)\n        except TypeError:\n            pass\n\n        raise TypeError('Cannot multiply %s and %s' % type(self), type(other))\n\n    @call_highest_priority('__sub__')\n    def __rsub__(self, a):\n        return (-self) + a\n\n    @call_highest_priority('__rsub__')\n    def __sub__(self, a):\n        return self + (-a)\n\n    @call_highest_priority('__rtruediv__')\n    def __truediv__(self, other):\n        return self.__div__(other)\n\n    def multiply_elementwise(self, other):\n        \"\"\"Return the Hadamard product (elementwise product) of A and B\n\n        Examples\n        ========\n\n        >>> from sympy.matrices import Matrix\n        >>> A = Matrix([[0, 1, 2], [3, 4, 5]])\n        >>> B = Matrix([[1, 10, 100], [100, 10, 1]])\n        >>> A.multiply_elementwise(B)\n        Matrix([\n        [  0, 10, 200],\n        [300, 40,   5]])\n\n        See Also\n        ========\n\n        cross\n        dot\n        multiply\n        \"\"\"\n        if self.shape != other.shape:\n            raise ShapeError(\"Matrix shapes must agree {} != {}\".format(self.shape, other.shape))\n\n        return self._eval_matrix_mul_elementwise(other)\n\n\nclass MatrixDeterminant(MatrixArithmetic, MatrixOperations, MatrixShaping):\n    \"\"\"Provides basic matrix determinant operations.\n    Should not be instantiated directly.\"\"\"\n\n    def _eval_berkowitz_toeplitz_matrix(self):\n        \"\"\"Return (A,T) where T the Toeplitz matrix used in the Berkowitz algorithm\n        corresponding to `self` and A is the first principal submatrix.\"\"\"\n\n        # the 0 x 0 case is trivial\n        if self.rows == 0 and self.cols == 0:\n            return self._new(1,1, [S.One])\n\n        #\n        # Partition self = [ a_11  R ]\n        #                  [ C     A ]\n        #\n\n        a, R = self[0,0],   self[0, 1:]\n        C, A = self[1:, 0], self[1:,1:]\n\n        #\n        # The Toeplitz matrix looks like\n        #\n        #  [ 1                                     ]\n        #  [ -a         1                          ]\n        #  [ -RC       -a        1                 ]\n        #  [ -RAC     -RC       -a       1         ]\n        #  [ -RA**2C -RAC      -RC      -a       1 ]\n        #  etc.\n\n        # Compute the diagonal entries.\n        # Because multiplying matrix times vector is so much\n        # more efficient than matrix times matrix, recursively\n        # compute -R * A**n * C.\n        diags = [C]\n        for i in range(self.rows - 2):\n            diags.append(A * diags[i])\n        diags = [(-R*d)[0, 0] for d in diags]\n        diags = [S.One, -a] + diags\n\n        def entry(i,j):\n            if j > i:\n                return S.Zero\n            return diags[i - j]\n\n        toeplitz = self._new(self.cols + 1, self.rows, entry)\n        return (A, toeplitz)\n\n    def _eval_berkowitz_vector(self):\n        \"\"\" Run the Berkowitz algorithm and return a vector whose entries\n            are the coefficients of the characteristic polynomial of `self`.\n\n            Given N x N matrix, efficiently compute\n            coefficients of characteristic polynomials of 'self'\n            without division in the ground domain.\n\n            This method is particularly useful for computing determinant,\n            principal minors and characteristic polynomial when 'self'\n            has complicated coefficients e.g. polynomials. Semi-direct\n            usage of this algorithm is also important in computing\n            efficiently sub-resultant PRS.\n\n            Assuming that M is a square matrix of dimension N x N and\n            I is N x N identity matrix, then the Berkowitz vector is\n            an N x 1 vector whose entries are coefficients of the\n            polynomial\n\n                           charpoly(M) = det(t*I - M)\n\n            As a consequence, all polynomials generated by Berkowitz\n            algorithm are monic.\n\n           For more information on the implemented algorithm refer to:\n\n           [1] S.J. Berkowitz, On computing the determinant in small\n               parallel time using a small number of processors, ACM,\n               Information Processing Letters 18, 1984, pp. 147-150\n\n           [2] M. Keber, Division-Free computation of sub-resultants\n               using Bezout matrices, Tech. Report MPI-I-2006-1-006,\n               Saarbrucken, 2006\n        \"\"\"\n\n        # handle the trivial cases\n        if self.rows == 0 and self.cols == 0:\n            return self._new(1, 1, [S.One])\n        elif self.rows == 1 and self.cols == 1:\n            return self._new(2, 1, [S.One, -self[0,0]])\n\n        submat, toeplitz = self._eval_berkowitz_toeplitz_matrix()\n        return toeplitz * submat._eval_berkowitz_vector()\n\n    def _eval_det_bareiss(self):\n        \"\"\"Compute matrix determinant using Bareiss' fraction-free\n        algorithm which is an extension of the well known Gaussian\n        elimination method. This approach is best suited for dense\n        symbolic matrices and will result in a determinant with\n        minimal number of fractions. It means that less term\n        rewriting is needed on resulting formulae.\n\n        TODO: Implement algorithm for sparse matrices (SFF),\n        http://www.eecis.udel.edu/~saunders/papers/sffge/it5.ps.\n        \"\"\"\n\n        # XXX included as a workaround for issue #12362.  Should use `_find_reasonable_pivot` instead\n        def _find_pivot(l):\n            for pos,val in enumerate(l):\n                if val:\n                    return (pos, val, None, None)\n            return (None, None, None, None)\n\n\n        # Recursively implimented Bareiss' algorithm as per Deanna Richelle Leggett's\n        # thesis http://www.math.usm.edu/perry/Research/Thesis_DRL.pdf\n        def bareiss(mat, cumm=1):\n            if mat.rows == 0:\n                return S.One\n            elif mat.rows == 1:\n                return mat[0, 0]\n\n            # find a pivot and extract the remaining matrix\n            # XXX should use `_find_reasonable_pivot`.  Blocked by issue #12362\n            pivot_pos, pivot_val, _, _ = _find_pivot(mat[:, 0])\n            if pivot_pos == None:\n                return S.Zero\n\n            # if we have a valid pivot, we'll do a \"row swap\", so keep the\n            # sign of the det\n            sign = (-1) ** (pivot_pos % 2)\n\n            # we want every row but the pivot row and every column\n            rows = list(i for i in range(mat.rows) if i != pivot_pos)\n            cols = list(range(mat.cols))\n            tmp_mat = mat.extract(rows, cols)\n\n            def entry(i, j):\n                ret = (pivot_val*tmp_mat[i, j + 1] - mat[pivot_pos, j + 1]*tmp_mat[i, 0]) / cumm\n                if not ret.is_Atom:\n                    cancel(ret)\n                return ret\n\n            return sign*bareiss(self._new(mat.rows - 1, mat.cols - 1, entry), pivot_val)\n\n        return cancel(bareiss(self))\n\n    def _eval_det_berkowitz(self):\n        \"\"\" Use the Berkowitz algorithm to compute the determinant.\"\"\"\n        berk_vector = self._eval_berkowitz_vector()\n        return (-1)**(len(berk_vector) - 1) * berk_vector[-1]\n\n    def _eval_det_lu(self):\n        \"\"\" Use LU the decomposition to compute the determinant.\"\"\"\n        try:\n            l, u, p = self.LUdecomposition()\n        except ValueError:\n            # if there is a value error in the LU decomposition, it means the matrix\n            # wasn't invertible\n            return S.Zero\n\n        # get the sign of the determinant\n        det = (-1) ** (len(p) % 2)\n        # multiply by the diagonal entries\n        for k in range(self.rows):\n            det *= l[k, k] * u[k, k]\n\n        return det\n\n    def adjugate(self, method=\"berkowitz\"):\n        \"\"\"Returns the adjugate, or classical adjoint, of\n        a matrix.  That is, the transpose of the matrix of cofactors.\n\n\n        http://en.wikipedia.org/wiki/Adjugate\n\n        See Also\n        ========\n\n        cofactor_matrix\n        transpose\n        \"\"\"\n        return self.cofactor_matrix(method).transpose()\n\n    def charpoly(self, x=Dummy('lambda'), simplify=_simplify):\n        \"\"\"Computes characteristic polynomial det(x*I - self) where I is\n        the identity matrix.\n\n        A PurePoly is returned, so using different variables for ``x`` does\n        not affect the comparison or the polynomials:\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix\n        >>> from sympy.abc import x, y\n        >>> A = Matrix([[1, 3], [2, 0]])\n        >>> A.charpoly(x) == A.charpoly(y)\n        True\n\n        Specifying ``x`` is optional; a Dummy with name ``lambda`` is used by\n        default (which looks good when pretty-printed in unicode):\n\n        >>> A.charpoly().as_expr()\n        _lambda**2 - _lambda - 6\n\n        No test is done to see that ``x`` doesn't clash with an existing\n        symbol, so using the default (``lambda``) or your own Dummy symbol is\n        the safest option:\n\n        >>> A = Matrix([[1, 2], [x, 0]])\n        >>> A.charpoly().as_expr()\n        _lambda**2 - _lambda - 2*x\n        >>> A.charpoly(x).as_expr()\n        x**2 - 3*x\n\n        Notes\n        =====\n\n        The Samuelson-Berkowitz algorithm is used to compute\n        the characteristic polynomial efficiently and without any\n        division operations.  Thus the characteristic polynomial over any\n        commutative ring without zero divisors can be computed.\n\n        See Also\n        ========\n\n        det\n        \"\"\"\n        berk_vector = self._eval_berkowitz_vector()\n        return PurePoly([simplify(a) for a in berk_vector], x)\n\n    def cofactor(self, i, j, method=\"berkowitz\"):\n        \"\"\"Calculate the cofactor of an element.\n\n        See Also\n        ========\n\n        cofactor_matrix\n        minor\n        minor_submatrix\n        \"\"\"\n\n        if self.rows != self.cols or self.rows < 1:\n            raise NonSquareMatrixError()\n\n        return (-1)**((i + j) % 2) * self.minor(i, j, method)\n\n    def cofactor_matrix(self, method=\"berkowitz\"):\n        \"\"\"Return a matrix containing the cofactor of each element.\n\n        See Also\n        ========\n\n        cofactor\n        minor\n        minor_submatrix\n        adjugate\n        \"\"\"\n\n        if self.rows != self.cols or self.rows < 1:\n            raise NonSquareMatrixError()\n\n        return self._new(self.rows, self.cols,\n                         lambda i, j: self.cofactor(i, j, method))\n\n    def det(self, method=\"bareiss\"):\n        \"\"\"Computes the determinant of a matrix.  If the matrix\n        is at most 3x3, a hard-coded formula is used.\n        Otherwise, the determinant using the method `method`.\n\n\n        Possible values for \"method\":\n          bareis\n          berkowitz\n          lu\n        \"\"\"\n\n        # sanitize `method`\n        method = method.lower()\n        if method == \"bareis\":\n            SymPyDeprecationWarning(\n                feature=\"Using 'bareis' to compute matrix determinant\",\n                useinstead=\"'bareiss'\",\n                issue=12363, deprecated_since_version=\"1.1\").warn()\n            method = \"bareiss\"\n        if method == \"det_lu\":\n            SymPyDeprecationWarning(\n                feature=\"Using 'det_lu' to compute matrix determinant\",\n                useinstead=\"'lu'\",\n                deprecated_since_version=\"1.1\").warn()\n            method = \"lu\"\n        if method not in (\"bareiss\", \"berkowitz\", \"lu\"):\n            raise ValueError(\"Determinant method '%s' unrecognized\" % method)\n\n        # if methods were made internal and all determinant calculations\n        # passed through here, then these lines could be factored out of\n        # the method routines\n        if self.rows != self.cols:\n            raise NonSquareMatrixError()\n\n        n = self.rows\n        if n == 0:\n            return S.One\n        elif n == 1:\n            return self[0,0]\n        elif n == 2:\n            return self[0, 0] * self[1, 1] - self[0, 1] * self[1, 0]\n        elif n == 3:\n            return  (self[0, 0] * self[1, 1] * self[2, 2]\n                   + self[0, 1] * self[1, 2] * self[2, 0]\n                   + self[0, 2] * self[1, 0] * self[2, 1]\n                   - self[0, 2] * self[1, 1] * self[2, 0]\n                   - self[0, 0] * self[1, 2] * self[2, 1]\n                   - self[0, 1] * self[1, 0] * self[2, 2])\n\n        if method == \"bareiss\":\n            return self._eval_det_bareiss()\n        elif method == \"berkowitz\":\n            return self._eval_det_berkowitz()\n        elif method == \"lu\":\n            return self._eval_det_lu()\n\n    def minor(self, i, j, method=\"berkowitz\"):\n        \"\"\"Return the (i,j) minor of `self`.  That is,\n        return the determinant of the matrix obtained by deleting\n        the `i`th row and `j`th column from `self`.\n\n        See Also\n        ========\n\n        minor_submatrix\n        cofactor\n        det\n        \"\"\"\n\n        if self.rows != self.cols or self.rows < 1:\n            raise NonSquareMatrixError()\n\n        return self.minor_submatrix(i, j).det(method=method)\n\n    def minor_submatrix(self, i, j):\n        \"\"\"Return the submatrix obtained by removing the `i`th row\n        and `j`th column from `self`.\n\n        See Also\n        ========\n\n        minor\n        cofactor\n        \"\"\"\n\n        if i < 0:\n            i += self.rows\n        if j < 0:\n            j += self.cols\n\n        if not 0 <= i < self.rows or not 0 <= j < self.cols:\n            raise ValueError(\"`i` and `j` must satisfy 0 <= i < `self.rows` \"\n                             \"(%d)\" % self.rows + \"and 0 <= j < `self.cols` (%d).\" % self.cols)\n\n        rows = [a for a in range(self.rows) if a != i]\n        cols = [a for a in range(self.cols) if a != j]\n        return self.extract(rows, cols)\n\n\nclass MatrixBase(MatrixDeterminant, MatrixArithmetic, MatrixOperations, MatrixProperties, MatrixShaping):\n    # Added just for numpy compatibility\n    __array_priority__ = 11\n\n    is_Matrix = True\n    _class_priority = 3\n    _sympify = staticmethod(sympify)\n\n    __hash__ = None  # Mutable\n\n    def __array__(self):\n        from .dense import matrix2numpy\n        return matrix2numpy(self)\n\n    def __getattr__(self, attr):\n        if attr in ('diff', 'integrate', 'limit'):\n            def doit(*args):\n                item_doit = lambda item: getattr(item, attr)(*args)\n                return self.applyfunc(item_doit)\n\n            return doit\n        else:\n            raise AttributeError(\n                \"%s has no attribute %s.\" % (self.__class__.__name__, attr))\n\n    def __len__(self):\n        \"\"\"Return the number of elements of self.\n\n        Implemented mainly so bool(Matrix()) == False.\n        \"\"\"\n        return self.rows * self.cols\n\n    def __mathml__(self):\n        mml = \"\"\n        for i in range(self.rows):\n            mml += \"<matrixrow>\"\n            for j in range(self.cols):\n                mml += self[i, j].__mathml__()\n            mml += \"</matrixrow>\"\n        return \"<matrix>\" + mml + \"</matrix>\"\n\n    # needed for python 2 compatibility\n    def __ne__(self, other):\n        return not self == other\n\n    def _matrix_pow_by_jordan_blocks(self, num):\n        from sympy.matrices import diag, MutableMatrix\n        from sympy import binomial\n\n        def jordan_cell_power(jc, n):\n            N = jc.shape[0]\n            l = jc[0, 0]\n            if l == 0 and (n < N - 1) != False:\n                raise ValueError(\"Matrix det == 0; not invertible\")\n            elif l == 0 and N > 1 and n % 1 != 0:\n                raise ValueError(\"Non-integer power cannot be evaluated\")\n            for i in range(N):\n                for j in range(N-i):\n                    bn = binomial(n, i)\n                    if isinstance(bn, binomial):\n                        bn = bn._eval_expand_func()\n                    jc[j, i+j] = l**(n-i)*bn\n\n        P, jordan_cells = self.jordan_cells()\n        # Make sure jordan_cells matrices are mutable:\n        jordan_cells = [MutableMatrix(j) for j in jordan_cells]\n        for j in jordan_cells:\n            jordan_cell_power(j, num)\n        return self._new(P*diag(*jordan_cells)*P.inv())\n\n    def _matrix_pow_by_recursion(self, num):\n        from sympy.matrices import eye\n        n = int(num)\n        if n < 0:\n            return self.inv()**-n   # A**-2 = (A**-1)**2\n        a = eye(self.cols)\n        s = self\n        while n:\n            if n % 2:\n                a *= s\n                n -= 1\n            if not n:\n                break\n            s *= s\n            n //= 2\n        return self._new(a)\n\n    def __repr__(self):\n        return sstr(self)\n\n    def __str__(self):\n        if self.rows == 0 or self.cols == 0:\n            return 'Matrix(%s, %s, [])' % (self.rows, self.cols)\n        return \"Matrix(%s)\" % str(self.tolist())\n\n    def _diagonalize_clear_subproducts(self):\n        del self._is_symbolic\n        del self._is_symmetric\n        del self._eigenvects\n\n    def _format_str(self, printer=None):\n        if not printer:\n            from sympy.printing.str import StrPrinter\n            printer = StrPrinter()\n        # Handle zero dimensions:\n        if self.rows == 0 or self.cols == 0:\n            return 'Matrix(%s, %s, [])' % (self.rows, self.cols)\n        if self.rows == 1:\n            return \"Matrix([%s])\" % self.table(printer, rowsep=',\\n')\n        return \"Matrix([\\n%s])\" % self.table(printer, rowsep=',\\n')\n\n    @classmethod\n    def _handle_creation_inputs(cls, *args, **kwargs):\n        \"\"\"Return the number of rows, cols and flat matrix elements.\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix, I\n\n        Matrix can be constructed as follows:\n\n        * from a nested list of iterables\n\n        >>> Matrix( ((1, 2+I), (3, 4)) )\n        Matrix([\n        [1, 2 + I],\n        [3,     4]])\n\n        * from un-nested iterable (interpreted as a column)\n\n        >>> Matrix( [1, 2] )\n        Matrix([\n        [1],\n        [2]])\n\n        * from un-nested iterable with dimensions\n\n        >>> Matrix(1, 2, [1, 2] )\n        Matrix([[1, 2]])\n\n        * from no arguments (a 0 x 0 matrix)\n\n        >>> Matrix()\n        Matrix(0, 0, [])\n\n        * from a rule\n\n        >>> Matrix(2, 2, lambda i, j: i/(j + 1) )\n        Matrix([\n        [0,   0],\n        [1, 1/2]])\n\n        \"\"\"\n        from sympy.matrices.sparse import SparseMatrix\n\n        flat_list = None\n\n        if len(args) == 1:\n            # Matrix(SparseMatrix(...))\n            if isinstance(args[0], SparseMatrix):\n                return args[0].rows, args[0].cols, flatten(args[0].tolist())\n\n            # Matrix(Matrix(...))\n            elif isinstance(args[0], MatrixBase):\n                return args[0].rows, args[0].cols, args[0]._mat\n\n            # Matrix(MatrixSymbol('X', 2, 2))\n            elif isinstance(args[0], Basic) and args[0].is_Matrix:\n                return args[0].rows, args[0].cols, args[0].as_explicit()._mat\n\n            # Matrix(numpy.ones((2, 2)))\n            elif hasattr(args[0], \"__array__\"):\n                # NumPy array or matrix or some other object that implements\n                # __array__. So let's first use this method to get a\n                # numpy.array() and then make a python list out of it.\n                arr = args[0].__array__()\n                if len(arr.shape) == 2:\n                    rows, cols = arr.shape[0], arr.shape[1]\n                    flat_list = [cls._sympify(i) for i in arr.ravel()]\n                    return rows, cols, flat_list\n                elif len(arr.shape) == 1:\n                    rows, cols = arr.shape[0], 1\n                    flat_list = [S.Zero] * rows\n                    for i in range(len(arr)):\n                        flat_list[i] = cls._sympify(arr[i])\n                    return rows, cols, flat_list\n                else:\n                    raise NotImplementedError(\n                        \"SymPy supports just 1D and 2D matrices\")\n\n            # Matrix([1, 2, 3]) or Matrix([[1, 2], [3, 4]])\n            elif is_sequence(args[0]) \\\n                    and not isinstance(args[0], DeferredVector):\n                in_mat = []\n                ncol = set()\n                for row in args[0]:\n                    if isinstance(row, MatrixBase):\n                        in_mat.extend(row.tolist())\n                        if row.cols or row.rows:  # only pay attention if it's not 0x0\n                            ncol.add(row.cols)\n                    else:\n                        in_mat.append(row)\n                        try:\n                            ncol.add(len(row))\n                        except TypeError:\n                            ncol.add(1)\n                if len(ncol) > 1:\n                    raise ValueError(\"Got rows of variable lengths: %s\" %\n                                     sorted(list(ncol)))\n                cols = ncol.pop() if ncol else 0\n                rows = len(in_mat) if cols else 0\n                if rows:\n                    if not is_sequence(in_mat[0]):\n                        cols = 1\n                        flat_list = [cls._sympify(i) for i in in_mat]\n                        return rows, cols, flat_list\n                flat_list = []\n                for j in range(rows):\n                    for i in range(cols):\n                        flat_list.append(cls._sympify(in_mat[j][i]))\n\n        elif len(args) == 3:\n            rows = as_int(args[0])\n            cols = as_int(args[1])\n\n            # Matrix(2, 2, lambda i, j: i+j)\n            if len(args) == 3 and isinstance(args[2], collections.Callable):\n                op = args[2]\n                flat_list = []\n                for i in range(rows):\n                    flat_list.extend(\n                        [cls._sympify(op(cls._sympify(i), cls._sympify(j)))\n                         for j in range(cols)])\n\n            # Matrix(2, 2, [1, 2, 3, 4])\n            elif len(args) == 3 and is_sequence(args[2]):\n                flat_list = args[2]\n                if len(flat_list) != rows * cols:\n                    raise ValueError(\n                        'List length should be equal to rows*columns')\n                flat_list = [cls._sympify(i) for i in flat_list]\n\n\n        # Matrix()\n        elif len(args) == 0:\n            # Empty Matrix\n            rows = cols = 0\n            flat_list = []\n\n        if flat_list is None:\n            raise TypeError(\"Data type not understood\")\n\n        return rows, cols, flat_list\n\n    def _jordan_block_structure(self):\n        # To every eigenvalue may belong `i` blocks with size s(i)\n        # and a chain of generalized eigenvectors\n        # which will be determined by the following computations:\n        # for every eigenvalue we will add a dictionary\n        # containing, for all blocks, the blocksizes and the attached chain vectors\n        # that will eventually be used to form the transformation P\n        jordan_block_structures = {}\n        _eigenvects = self.eigenvects()\n        ev = self.eigenvals()\n        if len(ev) == 0:\n            raise AttributeError(\"could not compute the eigenvalues\")\n        for eigenval, multiplicity, vects in _eigenvects:\n            l_jordan_chains = {}\n            geometrical = len(vects)\n            if geometrical == multiplicity:\n                # The Jordan chains have all length 1 and consist of only one vector\n                # which is the eigenvector of course\n                chains = []\n                for v in vects:\n                    chain = [v]\n                    chains.append(chain)\n                l_jordan_chains[1] = chains\n                jordan_block_structures[eigenval] = l_jordan_chains\n            elif geometrical == 0:\n                raise MatrixError(\n                    \"Matrix has the eigen vector with geometrical multiplicity equal zero.\")\n            else:\n                # Up to now we know nothing about the sizes of the blocks of our Jordan matrix.\n                # Note that knowledge of algebraic and geometrical multiplicity\n                # will *NOT* be sufficient to determine this structure.\n                # The blocksize `s` could be defined as the minimal `k` where\n                # `kernel(self-lI)^k = kernel(self-lI)^(k+1)`\n                # The extreme case would be that k = (multiplicity-geometrical+1)\n                # but the blocks could be smaller.\n\n                # Consider for instance the following matrix\n\n                # [2 1 0 0]\n                # [0 2 1 0]\n                # [0 0 2 0]\n                # [0 0 0 2]\n\n                # which coincides with it own Jordan canonical form.\n                # It has only one eigenvalue l=2 of (algebraic) multiplicity=4.\n                # It has two eigenvectors, one belonging to the last row (blocksize 1)\n                # and one being the last part of a jordan chain of length 3 (blocksize of the first block).\n\n                # Note again that it is not not possible to obtain this from the algebraic and geometrical\n                # multiplicity alone. This only gives us an upper limit for the dimension of one of\n                # the subspaces (blocksize of according jordan block) given by\n                # max=(multiplicity-geometrical+1) which is reached for our matrix\n                # but not for\n\n                # [2 1 0 0]\n                # [0 2 0 0]\n                # [0 0 2 1]\n                # [0 0 0 2]\n\n                # although multiplicity=4 and geometrical=2 are the same for this matrix.\n\n                from sympy.matrices import MutableMatrix\n                I = MutableMatrix.eye(self.rows)\n                l = eigenval\n                M = (self - l * I)\n\n                # We will store the matrices `(self-l*I)^k` for further computations\n                # for convenience only we store `Ms[0]=(sefl-lI)^0=I`\n                # so the index is the same as the power for all further Ms entries\n                # We also store the vectors that span these kernels (Ns[0] = [])\n                # and also their dimensions `a_s`\n                # this is mainly done for debugging since the number of blocks of a given size\n                # can be computed from the a_s, in order to check our result which is obtained simpler\n                # by counting the number of Jordan chains for `a` given `s`\n                # `a_0` is `dim(Kernel(Ms[0]) = dim (Kernel(I)) = 0` since `I` is regular\n\n                l_jordan_chains = {}\n                Ms = [I]\n                Ns = [[]]\n                a = [0]\n                smax = 0\n                M_new = Ms[-1] * M\n                Ns_new = M_new.nullspace()\n                a_new = len(Ns_new)\n                Ms.append(M_new)\n                Ns.append(Ns_new)\n                while a_new > a[\n                    -1]:  # as long as the nullspaces increase compute further powers\n                    a.append(a_new)\n                    M_new = Ms[-1] * M\n                    Ns_new = M_new.nullspace()\n                    a_new = len(Ns_new)\n                    Ms.append(M_new)\n                    Ns.append(Ns_new)\n                    smax += 1\n\n                # We now have `Ms[-1]=((self-l*I)**s)=Z=0`.\n                # We also know the size of the biggest Jordan block\n                # associated with `l` to be `s`.\n                # Now let us proceed with the computation of the associate part of the transformation matrix `P`.\n                # We already know the kernel (=nullspace)  `K_l` of (self-lI) which consists of the\n                # eigenvectors belonging to eigenvalue `l`.\n                # The dimension of this space is the geometric multiplicity of eigenvalue `l`.\n                # For every eigenvector ev out of `K_l`, there exists a subspace that is\n                # spanned by the Jordan chain of ev. The dimension of this subspace is\n                # represented by the length `s` of the Jordan block.\n                # The chain itself is given by `{e_0,..,e_s-1}` where:\n                # `e_k+1 =(self-lI)e_k (*)`\n                # and\n                # `e_s-1=ev`\n                # So it would be possible to start with the already known `ev` and work backwards until one\n                # reaches `e_0`. Unfortunately this can not be done by simply solving system (*) since its matrix\n                # is singular (by definition of the eigenspaces).\n                # This approach would force us a choose in every step the degree of freedom undetermined\n                # by (*). This is difficult to implement with computer algebra systems and also quite inefficient.\n                # We therefore reformulate the problem in terms of nullspaces.\n                # To do so we start from the other end and choose `e0`'s out of\n                # `E=Kernel(self-lI)^s / Kernel(self-lI)^(s-1)`\n                # Note that `Kernel(self-lI)^s = Kernel(Z) = V` (the whole vector space).\n                # So in the first step `s=smax` this restriction turns out to actually restrict nothing at all\n                # and the only remaining condition is to choose vectors in `Kernel(self-lI)^(s-1)`.\n                # Subsequently we compute `e_1=(self-lI)e_0`, `e_2=(self-lI)*e_1` and so on.\n                # The subspace `E` can have a dimension larger than one.\n                # That means that we have more than one Jordan block of size `s` for the eigenvalue `l`\n                # and as many Jordan chains (this is the case in the second example).\n                # In this case we start as many Jordan chains and have as many blocks of size `s` in the jcf.\n                # We now have all the Jordan blocks of size `s` but there might be others attached to the same\n                # eigenvalue that are smaller.\n                # So we will do the same procedure also for `s-1` and so on until 1 (the lowest possible order\n                # where the Jordan chain is of length 1 and just represented by the eigenvector).\n\n                for s in reversed(range(1, smax + 1)):\n                    S = Ms[s]\n                    # We want the vectors in `Kernel((self-lI)^s)`,\n                    # but without those in `Kernel(self-lI)^s-1`\n                    # so we will add their adjoints as additional equations\n                    # to the system formed by `S` to get the orthogonal\n                    # complement.\n                    # (`S` will no longer be quadratic.)\n\n                    exclude_vectors = Ns[s - 1]\n                    for k in range(0, a[s - 1]):\n                        S = S.col_join((exclude_vectors[k]).adjoint())\n\n                    # We also want to exclude the vectors\n                    # in the chains for the bigger blocks\n                    # that we have already computed (if there are any).\n                    # (That is why we start with the biggest s).\n\n                    # Since Jordan blocks are not orthogonal in general\n                    # (in the original space), only those chain vectors\n                    # that are on level s (index `s-1` in a chain)\n                    # are added.\n\n                    for chain_list in l_jordan_chains.values():\n                        for chain in chain_list:\n                            S = S.col_join(chain[s - 1].adjoint())\n\n                    e0s = S.nullspace()\n                    # Determine the number of chain leaders\n                    # for blocks of size `s`.\n                    n_e0 = len(e0s)\n                    s_chains = []\n                    # s_cells=[]\n                    for i in range(0, n_e0):\n                        chain = [e0s[i]]\n                        for k in range(1, s):\n                            v = M * chain[k - 1]\n                            chain.append(v)\n\n                        # We want the chain leader appear as the last of the block.\n                        chain.reverse()\n                        s_chains.append(chain)\n                    l_jordan_chains[s] = s_chains\n            jordan_block_structures[eigenval] = l_jordan_chains\n        return jordan_block_structures\n\n    def _jordan_split(self, algebraical, geometrical):\n        \"\"\"Return a list of integers with sum equal to 'algebraical'\n        and length equal to 'geometrical'\"\"\"\n        n1 = algebraical // geometrical\n        res = [n1] * geometrical\n        res[len(res) - 1] += algebraical % geometrical\n        assert sum(res) == algebraical\n        return res\n\n    def _setitem(self, key, value):\n        \"\"\"Helper to set value at location given by key.\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix, I, zeros, ones\n        >>> m = Matrix(((1, 2+I), (3, 4)))\n        >>> m\n        Matrix([\n        [1, 2 + I],\n        [3,     4]])\n        >>> m[1, 0] = 9\n        >>> m\n        Matrix([\n        [1, 2 + I],\n        [9,     4]])\n        >>> m[1, 0] = [[0, 1]]\n\n        To replace row r you assign to position r*m where m\n        is the number of columns:\n\n        >>> M = zeros(4)\n        >>> m = M.cols\n        >>> M[3*m] = ones(1, m)*2; M\n        Matrix([\n        [0, 0, 0, 0],\n        [0, 0, 0, 0],\n        [0, 0, 0, 0],\n        [2, 2, 2, 2]])\n\n        And to replace column c you can assign to position c:\n\n        >>> M[2] = ones(m, 1)*4; M\n        Matrix([\n        [0, 0, 4, 0],\n        [0, 0, 4, 0],\n        [0, 0, 4, 0],\n        [2, 2, 4, 2]])\n        \"\"\"\n        from .dense import Matrix\n\n        is_slice = isinstance(key, slice)\n        i, j = key = self.key2ij(key)\n        is_mat = isinstance(value, MatrixBase)\n        if type(i) is slice or type(j) is slice:\n            if is_mat:\n                self.copyin_matrix(key, value)\n                return\n            if not isinstance(value, Expr) and is_sequence(value):\n                self.copyin_list(key, value)\n                return\n            raise ValueError('unexpected value: %s' % value)\n        else:\n            if (not is_mat and\n                    not isinstance(value, Basic) and is_sequence(value)):\n                value = Matrix(value)\n                is_mat = True\n            if is_mat:\n                if is_slice:\n                    key = (slice(*divmod(i, self.cols)),\n                           slice(*divmod(j, self.cols)))\n                else:\n                    key = (slice(i, i + value.rows),\n                           slice(j, j + value.cols))\n                self.copyin_matrix(key, value)\n            else:\n                return i, j, self._sympify(value)\n            return\n\n    def add(self, b):\n        \"\"\"Return self + b \"\"\"\n        return self + b\n\n    def berkowitz_charpoly(self, x=Dummy('lambda'), simplify=_simplify):\n        \"\"\"Computes characteristic polynomial minors using Berkowitz method.\n\n        A PurePoly is returned so using different variables for ``x`` does\n        not affect the comparison or the polynomials:\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix\n        >>> from sympy.abc import x, y\n        >>> A = Matrix([[1, 3], [2, 0]])\n        >>> A.berkowitz_charpoly(x) == A.berkowitz_charpoly(y)\n        True\n\n        Specifying ``x`` is optional; a Dummy with name ``lambda`` is used by\n        default (which looks good when pretty-printed in unicode):\n\n        >>> A.berkowitz_charpoly().as_expr()\n        _lambda**2 - _lambda - 6\n\n        No test is done to see that ``x`` doesn't clash with an existing\n        symbol, so using the default (``lambda``) or your own Dummy symbol is\n        the safest option:\n\n        >>> A = Matrix([[1, 2], [x, 0]])\n        >>> A.charpoly().as_expr()\n        _lambda**2 - _lambda - 2*x\n        >>> A.charpoly(x).as_expr()\n        x**2 - 3*x\n\n        See Also\n        ========\n\n        berkowitz\n        \"\"\"\n        return PurePoly(list(map(simplify, self.berkowitz()[-1])), x)\n\n    def berkowitz_det(self):\n        \"\"\"Computes determinant using Berkowitz method.\n\n        See Also\n        ========\n\n        det\n        berkowitz\n        \"\"\"\n        if not self.is_square:\n            raise NonSquareMatrixError()\n        if not self:\n            return S.One\n        poly = self.berkowitz()[-1]\n        sign = (-1) ** (len(poly) - 1)\n        return sign * poly[-1]\n\n    def berkowitz_eigenvals(self, **flags):\n        \"\"\"Computes eigenvalues of a Matrix using Berkowitz method.\n\n        See Also\n        ========\n\n        berkowitz\n        \"\"\"\n        return roots(self.berkowitz_charpoly(Dummy('x')), **flags)\n\n    def berkowitz_minors(self):\n        \"\"\"Computes principal minors using Berkowitz method.\n\n        See Also\n        ========\n\n        berkowitz\n        \"\"\"\n        sign, minors = S.One, []\n\n        for poly in self.berkowitz():\n            minors.append(sign * poly[-1])\n            sign = -sign\n\n        return tuple(minors)\n\n    def berkowitz(self):\n        \"\"\"The Berkowitz algorithm.\n\n           Given N x N matrix with symbolic content, compute efficiently\n           coefficients of characteristic polynomials of 'self' and all\n           its square sub-matrices composed by removing both i-th row\n           and column, without division in the ground domain.\n\n           This method is particularly useful for computing determinant,\n           principal minors and characteristic polynomial, when 'self'\n           has complicated coefficients e.g. polynomials. Semi-direct\n           usage of this algorithm is also important in computing\n           efficiently sub-resultant PRS.\n\n           Assuming that M is a square matrix of dimension N x N and\n           I is N x N identity matrix,  then the following following\n           definition of characteristic polynomial is begin used:\n\n                          charpoly(M) = det(t*I - M)\n\n           As a consequence, all polynomials generated by Berkowitz\n           algorithm are monic.\n\n           >>> from sympy import Matrix\n           >>> from sympy.abc import x, y, z\n\n           >>> M = Matrix([[x, y, z], [1, 0, 0], [y, z, x]])\n\n           >>> p, q, r, s = M.berkowitz()\n\n           >>> p # 0 x 0 M's sub-matrix\n           (1,)\n\n           >>> q # 1 x 1 M's sub-matrix\n           (1, -x)\n\n           >>> r # 2 x 2 M's sub-matrix\n           (1, -x, -y)\n\n           >>> s # 3 x 3 M's sub-matrix\n           (1, -2*x, x**2 - y*z - y, x*y - z**2)\n\n           For more information on the implemented algorithm refer to:\n\n           [1] S.J. Berkowitz, On computing the determinant in small\n               parallel time using a small number of processors, ACM,\n               Information Processing Letters 18, 1984, pp. 147-150\n\n           [2] M. Keber, Division-Free computation of sub-resultants\n               using Bezout matrices, Tech. Report MPI-I-2006-1-006,\n               Saarbrucken, 2006\n\n        See Also\n        ========\n\n        berkowitz_det\n        berkowitz_minors\n        berkowitz_charpoly\n        berkowitz_eigenvals\n        \"\"\"\n        from sympy.matrices import zeros\n        berk = ((1,),)\n        if not self:\n            return berk\n\n        if not self.is_square:\n            raise NonSquareMatrixError()\n\n        A, N = self, self.rows\n        transforms = [0] * (N - 1)\n\n        for n in range(N, 1, -1):\n            T, k = zeros(n + 1, n), n - 1\n\n            R, C = -A[k, :k], A[:k, k]\n            A, a = A[:k, :k], -A[k, k]\n\n            items = [C]\n\n            for i in range(0, n - 2):\n                items.append(A * items[i])\n\n            for i, B in enumerate(items):\n                items[i] = (R * B)[0, 0]\n\n            items = [S.One, a] + items\n\n            for i in range(n):\n                T[i:, i] = items[:n - i + 1]\n\n            transforms[k - 1] = T\n\n        polys = [self._new([S.One, -A[0, 0]])]\n\n        for i, T in enumerate(transforms):\n            polys.append(T * polys[i])\n\n        return berk + tuple(map(tuple, polys))\n\n    def cholesky_solve(self, rhs):\n        \"\"\"Solves Ax = B using Cholesky decomposition,\n        for a general square non-singular matrix.\n        For a non-square matrix with rows > cols,\n        the least squares solution is returned.\n\n        See Also\n        ========\n\n        lower_triangular_solve\n        upper_triangular_solve\n        gauss_jordan_solve\n        diagonal_solve\n        LDLsolve\n        LUsolve\n        QRsolve\n        pinv_solve\n        \"\"\"\n        if self.is_symmetric():\n            L = self._cholesky()\n        elif self.rows >= self.cols:\n            L = (self.T * self)._cholesky()\n            rhs = self.T * rhs\n        else:\n            raise NotImplementedError('Under-determined System. '\n                                      'Try M.gauss_jordan_solve(rhs)')\n        Y = L._lower_triangular_solve(rhs)\n        return (L.T)._upper_triangular_solve(Y)\n\n    def cholesky(self):\n        \"\"\"Returns the Cholesky decomposition L of a matrix A\n        such that L * L.T = A\n\n        A must be a square, symmetric, positive-definite\n        and non-singular matrix.\n\n        Examples\n        ========\n\n        >>> from sympy.matrices import Matrix\n        >>> A = Matrix(((25, 15, -5), (15, 18, 0), (-5, 0, 11)))\n        >>> A.cholesky()\n        Matrix([\n        [ 5, 0, 0],\n        [ 3, 3, 0],\n        [-1, 1, 3]])\n        >>> A.cholesky() * A.cholesky().T\n        Matrix([\n        [25, 15, -5],\n        [15, 18,  0],\n        [-5,  0, 11]])\n\n        See Also\n        ========\n\n        LDLdecomposition\n        LUdecomposition\n        QRdecomposition\n        \"\"\"\n\n        if not self.is_square:\n            raise NonSquareMatrixError(\"Matrix must be square.\")\n        if not self.is_symmetric():\n            raise ValueError(\"Matrix must be symmetric.\")\n        return self._cholesky()\n\n    def cofactorMatrix(self, method=\"berkowitz\"):\n        return self.cofactor_matrix(method=method)\n\n    def columnspace(self, simplify=False):\n        \"\"\"Returns list of vectors (Matrix objects) that span columnspace of self\n\n        Examples\n        ========\n\n        >>> from sympy.matrices import Matrix\n        >>> m = Matrix(3, 3, [1, 3, 0, -2, -6, 0, 3, 9, 6])\n        >>> m\n        Matrix([\n        [ 1,  3, 0],\n        [-2, -6, 0],\n        [ 3,  9, 6]])\n        >>> m.columnspace()\n        [Matrix([\n        [ 1],\n        [-2],\n        [ 3]]), Matrix([\n        [0],\n        [0],\n        [6]])]\n\n        See Also\n        ========\n\n        nullspace\n        \"\"\"\n        simpfunc = simplify if isinstance(\n            simplify, FunctionType) else _simplify\n        reduced, pivots = self.rref(simplify=simpfunc)\n\n        basis = []\n        # create a set of vectors for the basis\n        for i in range(self.cols):\n            if i in pivots:\n                basis.append(self.col(i))\n        return [self._new(b) for b in basis]\n\n    def condition_number(self):\n        \"\"\"Returns the condition number of a matrix.\n\n        This is the maximum singular value divided by the minimum singular value\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix, S\n        >>> A = Matrix([[1, 0, 0], [0, 10, 0], [0, 0, S.One/10]])\n        >>> A.condition_number()\n        100\n\n        See Also\n        ========\n\n        singular_values\n        \"\"\"\n        if not self:\n            return S.Zero\n        singularvalues = self.singular_values()\n        return Max(*singularvalues) / Min(*singularvalues)\n\n    def copy(self):\n        \"\"\"\n        Returns the copy of a matrix.\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix\n        >>> A = Matrix(2, 2, [1, 2, 3, 4])\n        >>> A.copy()\n        Matrix([\n        [1, 2],\n        [3, 4]])\n\n        \"\"\"\n        return self._new(self.rows, self.cols, self._mat)\n\n    def cross(self, b):\n        \"\"\"Return the cross product of `self` and `b` relaxing the condition\n        of compatible dimensions: if each has 3 elements, a matrix of the\n        same type and shape as `self` will be returned. If `b` has the same\n        shape as `self` then common identities for the cross product (like\n        `a x b = - b x a`) will hold.\n\n        See Also\n        ========\n\n        dot\n        multiply\n        multiply_elementwise\n        \"\"\"\n        if not is_sequence(b):\n            raise TypeError(\n                \"`b` must be an ordered iterable or Matrix, not %s.\" %\n                type(b))\n        if not (self.rows * self.cols == b.rows * b.cols == 3):\n            raise ShapeError(\"Dimensions incorrect for cross product: %s x %s\" %\n                             ((self.rows, self.cols), (b.rows, b.cols)))\n        else:\n            return self._new(self.rows, self.cols, (\n                (self[1] * b[2] - self[2] * b[1]),\n                (self[2] * b[0] - self[0] * b[2]),\n                (self[0] * b[1] - self[1] * b[0])))\n\n    @property\n    def D(self):\n        \"\"\"Return Dirac conjugate (if self.rows == 4).\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix, I, eye\n        >>> m = Matrix((0, 1 + I, 2, 3))\n        >>> m.D\n        Matrix([[0, 1 - I, -2, -3]])\n        >>> m = (eye(4) + I*eye(4))\n        >>> m[0, 3] = 2\n        >>> m.D\n        Matrix([\n        [1 - I,     0,      0,      0],\n        [    0, 1 - I,      0,      0],\n        [    0,     0, -1 + I,      0],\n        [    2,     0,      0, -1 + I]])\n\n        If the matrix does not have 4 rows an AttributeError will be raised\n        because this property is only defined for matrices with 4 rows.\n\n        >>> Matrix(eye(2)).D\n        Traceback (most recent call last):\n        ...\n        AttributeError: Matrix has no attribute D.\n\n        See Also\n        ========\n\n        conjugate: By-element conjugation\n        H: Hermite conjugation\n        \"\"\"\n        from sympy.physics.matrices import mgamma\n        if self.rows != 4:\n            # In Python 3.2, properties can only return an AttributeError\n            # so we can't raise a ShapeError -- see commit which added the\n            # first line of this inline comment. Also, there is no need\n            # for a message since MatrixBase will raise the AttributeError\n            raise AttributeError\n        return self.H * mgamma(0)\n\n    @deprecated(useinstead=\"det_bareiss\", issue=12363, deprecated_since_version=\"1.1\")\n    def det_bareis(self):\n        return self.det_bareiss()\n\n    def det_bareiss(self):\n        \"\"\"Compute matrix determinant using Bareiss' fraction-free\n        algorithm which is an extension of the well known Gaussian\n        elimination method. This approach is best suited for dense\n        symbolic matrices and will result in a determinant with\n        minimal number of fractions. It means that less term\n        rewriting is needed on resulting formulae.\n\n        TODO: Implement algorithm for sparse matrices (SFF),\n        http://www.eecis.udel.edu/~saunders/papers/sffge/it5.ps.\n\n        See Also\n        ========\n\n        det\n        berkowitz_det\n        \"\"\"\n        if not self.is_square:\n            raise NonSquareMatrixError()\n        if not self:\n            return S.One\n\n        M, n = self.copy().as_mutable(), self.rows\n\n        if n == 1:\n            det = M[0, 0]\n        elif n == 2:\n            det = M[0, 0] * M[1, 1] - M[0, 1] * M[1, 0]\n        elif n == 3:\n            det = (\n                  M[0, 0] * M[1, 1] * M[2, 2] + M[0, 1] * M[1, 2] * M[2, 0] + M[\n                      0, 2] * M[1, 0] * M[2, 1]) - \\\n                  (\n                  M[0, 2] * M[1, 1] * M[2, 0] + M[0, 0] * M[1, 2] * M[2, 1] + M[\n                      0, 1] * M[1, 0] * M[2, 2])\n        else:\n            sign = 1  # track current sign in case of column swap\n\n            for k in range(n - 1):\n                # look for a pivot in the current column\n                # and assume det == 0 if none is found\n                if M[k, k] == 0:\n                    for i in range(k + 1, n):\n                        if M[i, k]:\n                            M.row_swap(i, k)\n                            sign *= -1\n                            break\n                    else:\n                        return S.Zero\n\n                # proceed with Bareiss' fraction-free (FF)\n                # form of Gaussian elimination algorithm\n                for i in range(k + 1, n):\n                    for j in range(k + 1, n):\n                        D = M[k, k] * M[i, j] - M[i, k] * M[k, j]\n\n                        if k > 0:\n                            D /= M[k - 1, k - 1]\n\n                        if D.is_Atom:\n                            M[i, j] = D\n                        else:\n                            M[i, j] = cancel(D)\n\n            det = sign * M[n - 1, n - 1]\n\n        return det.expand()\n\n    def det_LU_decomposition(self):\n        \"\"\"Compute matrix determinant using LU decomposition\n\n\n        Note that this method fails if the LU decomposition itself\n        fails. In particular, if the matrix has no inverse this method\n        will fail.\n\n        TODO: Implement algorithm for sparse matrices (SFF),\n        http://www.eecis.udel.edu/~saunders/papers/sffge/it5.ps.\n\n        See Also\n        ========\n\n\n        det\n        det_bareiss\n        berkowitz_det\n        \"\"\"\n        if not self.is_square:\n            raise NonSquareMatrixError()\n        if not self:\n            return S.One\n\n        M, n = self.copy(), self.rows\n        p, prod = [], 1\n        l, u, p = M.LUdecomposition()\n        if len(p) % 2:\n            prod = -1\n\n        for k in range(n):\n            prod = prod * u[k, k] * l[k, k]\n\n        return prod.expand()\n\n    def diagonal_solve(self, rhs):\n        \"\"\"Solves Ax = B efficiently, where A is a diagonal Matrix,\n        with non-zero diagonal entries.\n\n        Examples\n        ========\n\n        >>> from sympy.matrices import Matrix, eye\n        >>> A = eye(2)*2\n        >>> B = Matrix([[1, 2], [3, 4]])\n        >>> A.diagonal_solve(B) == B/2\n        True\n\n        See Also\n        ========\n\n        lower_triangular_solve\n        upper_triangular_solve\n        gauss_jordan_solve\n        cholesky_solve\n        LDLsolve\n        LUsolve\n        QRsolve\n        pinv_solve\n        \"\"\"\n        if not self.is_diagonal:\n            raise TypeError(\"Matrix should be diagonal\")\n        if rhs.rows != self.rows:\n            raise TypeError(\"Size mis-match\")\n        return self._diagonal_solve(rhs)\n\n    def diagonalize(self, reals_only=False, sort=False, normalize=False):\n        \"\"\"\n        Return (P, D), where D is diagonal and\n\n            D = P^-1 * M * P\n\n        where M is current matrix.\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix\n        >>> m = Matrix(3, 3, [1, 2, 0, 0, 3, 0, 2, -4, 2])\n        >>> m\n        Matrix([\n        [1,  2, 0],\n        [0,  3, 0],\n        [2, -4, 2]])\n        >>> (P, D) = m.diagonalize()\n        >>> D\n        Matrix([\n        [1, 0, 0],\n        [0, 2, 0],\n        [0, 0, 3]])\n        >>> P\n        Matrix([\n        [-1, 0, -1],\n        [ 0, 0, -1],\n        [ 2, 1,  2]])\n        >>> P.inv() * m * P\n        Matrix([\n        [1, 0, 0],\n        [0, 2, 0],\n        [0, 0, 3]])\n\n        See Also\n        ========\n\n        is_diagonal\n        is_diagonalizable\n\n        \"\"\"\n        from sympy.matrices import diag\n\n        if not self.is_square:\n            raise NonSquareMatrixError()\n        if not self.is_diagonalizable(reals_only, False):\n            self._diagonalize_clear_subproducts()\n            raise MatrixError(\"Matrix is not diagonalizable\")\n        else:\n            if self._eigenvects is None:\n                self._eigenvects = self.eigenvects(simplify=True)\n            if sort:\n                self._eigenvects.sort(key=default_sort_key)\n                self._eigenvects.reverse()\n            diagvals = []\n            P = self._new(self.rows, 0, [])\n            for eigenval, multiplicity, vects in self._eigenvects:\n                for k in range(multiplicity):\n                    diagvals.append(eigenval)\n                    vec = vects[k]\n                    if normalize:\n                        vec = vec / vec.norm()\n                    P = P.col_insert(P.cols, vec)\n            D = diag(*diagvals)\n            self._diagonalize_clear_subproducts()\n            return (P, D)\n\n    def diff(self, *args):\n        \"\"\"Calculate the derivative of each element in the matrix.\n\n        Examples\n        ========\n\n        >>> from sympy.matrices import Matrix\n        >>> from sympy.abc import x, y\n        >>> M = Matrix([[x, y], [1, 0]])\n        >>> M.diff(x)\n        Matrix([\n        [1, 0],\n        [0, 0]])\n\n        See Also\n        ========\n\n        integrate\n        limit\n        \"\"\"\n        return self._new(self.rows, self.cols,\n                         lambda i, j: self[i, j].diff(*args))\n\n    def dot(self, b):\n        \"\"\"Return the dot product of Matrix self and b relaxing the condition\n        of compatible dimensions: if either the number of rows or columns are\n        the same as the length of b then the dot product is returned. If self\n        is a row or column vector, a scalar is returned. Otherwise, a list\n        of results is returned (and in that case the number of columns in self\n        must match the length of b).\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix\n        >>> M = Matrix([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n        >>> v = [1, 1, 1]\n        >>> M.row(0).dot(v)\n        6\n        >>> M.col(0).dot(v)\n        12\n        >>> M.dot(v)\n        [6, 15, 24]\n\n        See Also\n        ========\n\n        cross\n        multiply\n        multiply_elementwise\n        \"\"\"\n        from .dense import Matrix\n\n        if not isinstance(b, MatrixBase):\n            if is_sequence(b):\n                if len(b) != self.cols and len(b) != self.rows:\n                    raise ShapeError(\n                        \"Dimensions incorrect for dot product: %s, %s\" % (\n                            self.shape, len(b)))\n                return self.dot(Matrix(b))\n            else:\n                raise TypeError(\n                    \"`b` must be an ordered iterable or Matrix, not %s.\" %\n                    type(b))\n\n        mat = self\n        if mat.cols == b.rows:\n            if b.cols != 1:\n                mat = mat.T\n                b = b.T\n            prod = flatten((mat * b).tolist())\n            if len(prod) == 1:\n                return prod[0]\n            return prod\n        if mat.cols == b.cols:\n            return mat.dot(b.T)\n        elif mat.rows == b.rows:\n            return mat.T.dot(b)\n        else:\n            raise ShapeError(\"Dimensions incorrect for dot product: %s, %s\" % (\n                self.shape, b.shape))\n\n    def dual(self):\n        \"\"\"Returns the dual of a matrix, which is:\n\n        `(1/2)*levicivita(i, j, k, l)*M(k, l)` summed over indices `k` and `l`\n\n        Since the levicivita method is anti_symmetric for any pairwise\n        exchange of indices, the dual of a symmetric matrix is the zero\n        matrix. Strictly speaking the dual defined here assumes that the\n        'matrix' `M` is a contravariant anti_symmetric second rank tensor,\n        so that the dual is a covariant second rank tensor.\n\n        \"\"\"\n        from sympy import LeviCivita\n        from sympy.matrices import zeros\n\n        M, n = self[:, :], self.rows\n        work = zeros(n)\n        if self.is_symmetric():\n            return work\n\n        for i in range(1, n):\n            for j in range(1, n):\n                acum = 0\n                for k in range(1, n):\n                    acum += LeviCivita(i, j, 0, k) * M[0, k]\n                work[i, j] = acum\n                work[j, i] = -acum\n\n        for l in range(1, n):\n            acum = 0\n            for a in range(1, n):\n                for b in range(1, n):\n                    acum += LeviCivita(0, l, a, b) * M[a, b]\n            acum /= 2\n            work[0, l] = -acum\n            work[l, 0] = acum\n\n        return work\n\n    def eigenvals(self, **flags):\n        \"\"\"Return eigen values using the berkowitz_eigenvals routine.\n\n        Since the roots routine doesn't always work well with Floats,\n        they will be replaced with Rationals before calling that\n        routine. If this is not desired, set flag ``rational`` to False.\n        \"\"\"\n        # roots doesn't like Floats, so replace them with Rationals\n        # unless the nsimplify flag indicates that this has already\n        # been done, e.g. in eigenvects\n        mat = self\n\n        if not mat:\n            return {}\n        if flags.pop('rational', True):\n            if any(v.has(Float) for v in mat):\n                mat = mat._new(mat.rows, mat.cols,\n                               [nsimplify(v, rational=True) for v in mat])\n\n        flags.pop('simplify', None)  # pop unsupported flag\n        return mat.berkowitz_eigenvals(**flags)\n\n    def eigenvects(self, **flags):\n        \"\"\"Return list of triples (eigenval, multiplicity, basis).\n\n        The flag ``simplify`` has two effects:\n            1) if bool(simplify) is True, as_content_primitive()\n            will be used to tidy up normalization artifacts;\n            2) if nullspace needs simplification to compute the\n            basis, the simplify flag will be passed on to the\n            nullspace routine which will interpret it there.\n\n        If the matrix contains any Floats, they will be changed to Rationals\n        for computation purposes, but the answers will be returned after being\n        evaluated with evalf. If it is desired to removed small imaginary\n        portions during the evalf step, pass a value for the ``chop`` flag.\n        \"\"\"\n        from sympy.matrices import eye\n\n        simplify = flags.get('simplify', True)\n        primitive = bool(flags.get('simplify', False))\n        chop = flags.pop('chop', False)\n\n        flags.pop('multiple', None)  # remove this if it's there\n\n        # roots doesn't like Floats, so replace them with Rationals\n        float = False\n        mat = self\n        if any(v.has(Float) for v in self):\n            float = True\n            mat = mat._new(mat.rows, mat.cols, [nsimplify(\n                v, rational=True) for v in mat])\n            flags['rational'] = False  # to tell eigenvals not to do this\n\n        out, vlist = [], mat.eigenvals(**flags)\n        vlist = list(vlist.items())\n        vlist.sort(key=default_sort_key)\n        flags.pop('rational', None)\n\n        for r, k in vlist:\n            tmp = mat.as_mutable() - eye(mat.rows) * r\n            basis = tmp.nullspace()\n            # whether tmp.is_symbolic() is True or False, it is possible that\n            # the basis will come back as [] in which case simplification is\n            # necessary.\n            if not basis:\n                # The nullspace routine failed, try it again with simplification\n                basis = tmp.nullspace(simplify=simplify)\n                if not basis:\n                    raise NotImplementedError(\n                        \"Can't evaluate eigenvector for eigenvalue %s\" % r)\n            if primitive:\n                # the relationship A*e = lambda*e will still hold if we change the\n                # eigenvector; so if simplify is True we tidy up any normalization\n                # artifacts with as_content_primtive (default) and remove any pure Integer\n                # denominators.\n                l = 1\n                for i, b in enumerate(basis[0]):\n                    c, p = signsimp(b).as_content_primitive()\n                    if c is not S.One:\n                        b = c * p\n                        l = ilcm(l, c.q)\n                    basis[0][i] = b\n                if l != 1:\n                    basis[0] *= l\n            if float:\n                out.append((r.evalf(chop=chop), k, [\n                    mat._new(b).evalf(chop=chop) for b in basis]))\n            else:\n                out.append((r, k, [mat._new(b) for b in basis]))\n        return out\n\n    def exp(self):\n        \"\"\"Return the exponentiation of a square matrix.\"\"\"\n        if not self.is_square:\n            raise NonSquareMatrixError(\n                \"Exponentiation is valid only for square matrices\")\n        try:\n            P, cells = self.jordan_cells()\n        except MatrixError:\n            raise NotImplementedError(\n                \"Exponentiation is implemented only for matrices for which the Jordan normal form can be computed\")\n\n        def _jblock_exponential(b):\n            # This function computes the matrix exponential for one single Jordan block\n            nr = b.rows\n            l = b[0, 0]\n            if nr == 1:\n                res = exp(l)\n            else:\n                from sympy import eye\n                # extract the diagonal part\n                d = b[0, 0] * eye(nr)\n                # and the nilpotent part\n                n = b - d\n                # compute its exponential\n                nex = eye(nr)\n                for i in range(1, nr):\n                    nex = nex + n ** i / factorial(i)\n                # combine the two parts\n                res = exp(b[0, 0]) * nex\n            return (res)\n\n        blocks = list(map(_jblock_exponential, cells))\n        from sympy.matrices import diag\n        eJ = diag(*blocks)\n        # n = self.rows\n        ret = P * eJ * P.inv()\n        return type(self)(ret)\n\n    def gauss_jordan_solve(self, b, freevar=False):\n        \"\"\"\n        Solves Ax = b using Gauss Jordan elimination.\n\n        There may be zero, one, or infinite solutions.  If one solution\n        exists, it will be returned. If infinite solutions exist, it will\n        be returned parametrically. If no solutions exist, It will throw\n        ValueError.\n\n        Parameters\n        ==========\n\n        b : Matrix\n            The right hand side of the equation to be solved for.  Must have\n            the same number of rows as matrix A.\n\n        freevar : List\n            If the system is underdetermined (e.g. A has more columns than\n            rows), infinite solutions are possible, in terms of an arbitrary\n            values of free variables. Then the index of the free variables\n            in the solutions (column Matrix) will be returned by freevar, if\n            the flag `freevar` is set to `True`.\n\n        Returns\n        =======\n\n        x : Matrix\n            The matrix that will satisfy Ax = B.  Will have as many rows as\n            matrix A has columns, and as many columns as matrix B.\n\n        params : Matrix\n            If the system is underdetermined (e.g. A has more columns than\n            rows), infinite solutions are possible, in terms of an arbitrary\n            parameters. These arbitrary parameters are returned as params\n            Matrix.\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix\n        >>> A = Matrix([[1, 2, 1, 1], [1, 2, 2, -1], [2, 4, 0, 6]])\n        >>> b = Matrix([7, 12, 4])\n        >>> sol, params = A.gauss_jordan_solve(b)\n        >>> sol\n        Matrix([\n        [-2*_tau0 - 3*_tau1 + 2],\n        [                 _tau0],\n        [           2*_tau1 + 5],\n        [                 _tau1]])\n        >>> params\n        Matrix([\n        [_tau0],\n        [_tau1]])\n\n        >>> A = Matrix([[1, 2, 3], [4, 5, 6], [7, 8, 10]])\n        >>> b = Matrix([3, 6, 9])\n        >>> sol, params = A.gauss_jordan_solve(b)\n        >>> sol\n        Matrix([\n        [-1],\n        [ 2],\n        [ 0]])\n        >>> params\n        Matrix(0, 1, [])\n\n        See Also\n        ========\n\n        lower_triangular_solve\n        upper_triangular_solve\n        cholesky_solve\n        diagonal_solve\n        LDLsolve\n        LUsolve\n        QRsolve\n        pinv\n\n        References\n        ==========\n\n        .. [1] http://en.wikipedia.org/wiki/Gaussian_elimination\n\n        \"\"\"\n        from sympy.matrices import Matrix, zeros\n\n        aug = self.hstack(self.copy(), b.copy())\n        row, col = aug[:, :-1].shape\n\n        # solve by reduced row echelon form\n        A, pivots = aug.rref(simplify=True)\n        A, v = A[:, :-1], A[:, -1]\n        pivots = list(filter(lambda p: p < col, pivots))\n        rank = len(pivots)\n\n        # Bring to block form\n        permutation = Matrix(range(col)).T\n        A = A.vstack(A, permutation)\n\n        for i, c in enumerate(pivots):\n            A.col_swap(i, c)\n\n        A, permutation = A[:-1, :], A[-1, :]\n\n        # check for existence of solutions\n        # rank of aug Matrix should be equal to rank of coefficient matrix\n        if not v[rank:, 0].is_zero:\n            raise ValueError(\"Linear system has no solution\")\n\n        # Get index of free symbols (free parameters)\n        free_var_index = permutation[\n                         len(pivots):]  # non-pivots columns are free variables\n\n        # Free parameters\n        dummygen = numbered_symbols(\"tau\", Dummy)\n        tau = Matrix([next(dummygen) for k in range(col - rank)]).reshape(\n            col - rank, 1)\n\n        # Full parametric solution\n        V = A[:rank, rank:]\n        vt = v[:rank, 0]\n        free_sol = tau.vstack(vt - V * tau, tau)\n\n        # Undo permutation\n        sol = zeros(col, 1)\n        for k, v in enumerate(free_sol):\n            sol[permutation[k], 0] = v\n\n        if freevar:\n            return sol, tau, free_var_index\n        else:\n            return sol, tau\n\n    @classmethod\n    def hstack(cls, *args):\n        \"\"\"Return a matrix formed by joining args horizontally (i.e.\n        by repeated application of row_join).\n\n        Examples\n        ========\n\n        >>> from sympy.matrices import Matrix, eye\n        >>> Matrix.hstack(eye(2), 2*eye(2))\n        Matrix([\n        [1, 0, 2, 0],\n        [0, 1, 0, 2]])\n        \"\"\"\n        kls = type(args[0])\n        return reduce(kls.row_join, args)\n\n    def integrate(self, *args):\n        \"\"\"Integrate each element of the matrix.\n\n        Examples\n        ========\n\n        >>> from sympy.matrices import Matrix\n        >>> from sympy.abc import x, y\n        >>> M = Matrix([[x, y], [1, 0]])\n        >>> M.integrate((x, ))\n        Matrix([\n        [x**2/2, x*y],\n        [     x,   0]])\n        >>> M.integrate((x, 0, 2))\n        Matrix([\n        [2, 2*y],\n        [2,   0]])\n\n        See Also\n        ========\n\n        limit\n        diff\n        \"\"\"\n        return self._new(self.rows, self.cols,\n                         lambda i, j: self[i, j].integrate(*args))\n\n    def inv_mod(self, m):\n        \"\"\"\n        Returns the inverse of the matrix `K` (mod `m`), if it exists.\n\n        Method to find the matrix inverse of `K` (mod `m`) implemented in this function:\n\n        * Compute `\\mathrm{adj}(K) = \\mathrm{cof}(K)^t`, the adjoint matrix of `K`.\n\n        * Compute `r = 1/\\mathrm{det}(K) \\pmod m`.\n\n        * `K^{-1} = r\\cdot \\mathrm{adj}(K) \\pmod m`.\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix\n        >>> A = Matrix(2, 2, [1, 2, 3, 4])\n        >>> A.inv_mod(5)\n        Matrix([\n        [3, 1],\n        [4, 2]])\n        >>> A.inv_mod(3)\n        Matrix([\n        [1, 1],\n        [0, 1]])\n\n        \"\"\"\n        from sympy.ntheory import totient\n        if not self.is_square:\n            raise NonSquareMatrixError()\n        N = self.cols\n        phi = totient(m)\n        det_K = self.det()\n        if gcd(det_K, m) != 1:\n            raise ValueError('Matrix is not invertible (mod %d)' % m)\n        det_inv = pow(int(det_K), int(phi - 1), int(m))\n        K_adj = self.cofactorMatrix().transpose()\n        K_inv = self.__class__(N, N,\n                               [det_inv * K_adj[i, j] % m for i in range(N) for\n                                j in range(N)])\n        return K_inv\n\n    def inverse_ADJ(self, iszerofunc=_iszero):\n        \"\"\"Calculates the inverse using the adjugate matrix and a determinant.\n\n        See Also\n        ========\n\n        inv\n        inverse_LU\n        inverse_GE\n        \"\"\"\n        if not self.is_square:\n            raise NonSquareMatrixError(\"A Matrix must be square to invert.\")\n\n        d = self.berkowitz_det()\n        zero = d.equals(0)\n        if zero is None:\n            # if equals() can't decide, will rref be able to?\n            ok = self.rref(simplify=True)[0]\n            zero = any(iszerofunc(ok[j, j]) for j in range(ok.rows))\n        if zero:\n            raise ValueError(\"Matrix det == 0; not invertible.\")\n\n        return self.adjugate() / d\n\n    def inverse_GE(self, iszerofunc=_iszero):\n        \"\"\"Calculates the inverse using Gaussian elimination.\n\n        See Also\n        ========\n\n        inv\n        inverse_LU\n        inverse_ADJ\n        \"\"\"\n        from .dense import Matrix\n        if not self.is_square:\n            raise NonSquareMatrixError(\"A Matrix must be square to invert.\")\n\n        big = Matrix.hstack(self.as_mutable(), Matrix.eye(self.rows))\n        red = big.rref(iszerofunc=iszerofunc, simplify=True)[0]\n        if any(iszerofunc(red[j, j]) for j in range(red.rows)):\n            raise ValueError(\"Matrix det == 0; not invertible.\")\n\n        return self._new(red[:, big.rows:])\n\n    def inverse_LU(self, iszerofunc=_iszero):\n        \"\"\"Calculates the inverse using LU decomposition.\n\n        See Also\n        ========\n\n        inv\n        inverse_GE\n        inverse_ADJ\n        \"\"\"\n        if not self.is_square:\n            raise NonSquareMatrixError()\n\n        ok = self.rref(simplify=True)[0]\n        if any(iszerofunc(ok[j, j]) for j in range(ok.rows)):\n            raise ValueError(\"Matrix det == 0; not invertible.\")\n\n        return self.LUsolve(self.eye(self.rows), iszerofunc=_iszero)\n\n    def inv(self, method=None, **kwargs):\n        \"\"\"\n        Return the inverse of a matrix.\n\n        CASE 1: If the matrix is a dense matrix.\n\n        Return the matrix inverse using the method indicated (default\n        is Gauss elimination).\n\n        kwargs\n        ======\n\n        method : ('GE', 'LU', or 'ADJ')\n\n        Notes\n        =====\n\n        According to the ``method`` keyword, it calls the appropriate method:\n\n          GE .... inverse_GE(); default\n          LU .... inverse_LU()\n          ADJ ... inverse_ADJ()\n\n        See Also\n        ========\n\n        inverse_LU\n        inverse_GE\n        inverse_ADJ\n\n        Raises\n        ------\n        ValueError\n            If the determinant of the matrix is zero.\n\n        CASE 2: If the matrix is a sparse matrix.\n\n        Return the matrix inverse using Cholesky or LDL (default).\n\n        kwargs\n        ======\n\n        method : ('CH', 'LDL')\n\n        Notes\n        =====\n\n        According to the ``method`` keyword, it calls the appropriate method:\n\n          LDL ... inverse_LDL(); default\n          CH .... inverse_CH()\n\n        Raises\n        ------\n        ValueError\n            If the determinant of the matrix is zero.\n\n        \"\"\"\n        if not self.is_square:\n            raise NonSquareMatrixError()\n        if method is not None:\n            kwargs['method'] = method\n        return self._eval_inverse(**kwargs)\n\n    def is_diagonalizable(self, reals_only=False, clear_subproducts=True):\n        \"\"\"Check if matrix is diagonalizable.\n\n        If reals_only==True then check that diagonalized matrix consists of the only not complex values.\n\n        Some subproducts could be used further in other methods to avoid double calculations,\n        By default (if clear_subproducts==True) they will be deleted.\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix\n        >>> m = Matrix(3, 3, [1, 2, 0, 0, 3, 0, 2, -4, 2])\n        >>> m\n        Matrix([\n        [1,  2, 0],\n        [0,  3, 0],\n        [2, -4, 2]])\n        >>> m.is_diagonalizable()\n        True\n        >>> m = Matrix(2, 2, [0, 1, 0, 0])\n        >>> m\n        Matrix([\n        [0, 1],\n        [0, 0]])\n        >>> m.is_diagonalizable()\n        False\n        >>> m = Matrix(2, 2, [0, 1, -1, 0])\n        >>> m\n        Matrix([\n        [ 0, 1],\n        [-1, 0]])\n        >>> m.is_diagonalizable()\n        True\n        >>> m.is_diagonalizable(True)\n        False\n\n        See Also\n        ========\n\n        is_diagonal\n        diagonalize\n        \"\"\"\n        if not self.is_square:\n            return False\n        res = False\n        self._is_symbolic = self.is_symbolic()\n        self._is_symmetric = self.is_symmetric()\n        self._eigenvects = None\n        self._eigenvects = self.eigenvects(simplify=True)\n        all_iscorrect = True\n        for eigenval, multiplicity, vects in self._eigenvects:\n            if len(vects) != multiplicity:\n                all_iscorrect = False\n                break\n            elif reals_only and not eigenval.is_real:\n                all_iscorrect = False\n                break\n        res = all_iscorrect\n        if clear_subproducts:\n            self._diagonalize_clear_subproducts()\n        return res\n\n    def is_nilpotent(self):\n        \"\"\"Checks if a matrix is nilpotent.\n\n        A matrix B is nilpotent if for some integer k, B**k is\n        a zero matrix.\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix\n        >>> a = Matrix([[0, 0, 0], [1, 0, 0], [1, 1, 0]])\n        >>> a.is_nilpotent()\n        True\n\n        >>> a = Matrix([[1, 0, 1], [1, 0, 0], [1, 1, 0]])\n        >>> a.is_nilpotent()\n        False\n        \"\"\"\n        if not self:\n            return True\n        if not self.is_square:\n            raise NonSquareMatrixError(\n                \"Nilpotency is valid only for square matrices\")\n        x = Dummy('x')\n        if self.charpoly(x).args[0] == x ** self.rows:\n            return True\n        return False\n\n    def jacobian(self, X):\n        \"\"\"Calculates the Jacobian matrix (derivative of a vectorial function).\n\n        Parameters\n        ==========\n\n        self : vector of expressions representing functions f_i(x_1, ..., x_n).\n        X : set of x_i's in order, it can be a list or a Matrix\n\n        Both self and X can be a row or a column matrix in any order\n        (i.e., jacobian() should always work).\n\n        Examples\n        ========\n\n        >>> from sympy import sin, cos, Matrix\n        >>> from sympy.abc import rho, phi\n        >>> X = Matrix([rho*cos(phi), rho*sin(phi), rho**2])\n        >>> Y = Matrix([rho, phi])\n        >>> X.jacobian(Y)\n        Matrix([\n        [cos(phi), -rho*sin(phi)],\n        [sin(phi),  rho*cos(phi)],\n        [   2*rho,             0]])\n        >>> X = Matrix([rho*cos(phi), rho*sin(phi)])\n        >>> X.jacobian(Y)\n        Matrix([\n        [cos(phi), -rho*sin(phi)],\n        [sin(phi),  rho*cos(phi)]])\n\n        See Also\n        ========\n\n        hessian\n        wronskian\n        \"\"\"\n        if not isinstance(X, MatrixBase):\n            X = self._new(X)\n        # Both X and self can be a row or a column matrix, so we need to make\n        # sure all valid combinations work, but everything else fails:\n        if self.shape[0] == 1:\n            m = self.shape[1]\n        elif self.shape[1] == 1:\n            m = self.shape[0]\n        else:\n            raise TypeError(\"self must be a row or a column matrix\")\n        if X.shape[0] == 1:\n            n = X.shape[1]\n        elif X.shape[1] == 1:\n            n = X.shape[0]\n        else:\n            raise TypeError(\"X must be a row or a column matrix\")\n\n        # m is the number of functions and n is the number of variables\n        # computing the Jacobian is now easy:\n        return self._new(m, n, lambda j, i: self[j].diff(X[i]))\n\n    def jordan_cell(self, eigenval, n):\n        n = int(n)\n        from sympy.matrices import MutableMatrix\n        out = MutableMatrix.zeros(n)\n        for i in range(n - 1):\n            out[i, i] = eigenval\n            out[i, i + 1] = 1\n        out[n - 1, n - 1] = eigenval\n        return type(self)(out)\n\n    def jordan_cells(self, calc_transformation=True):\n        r\"\"\"Return a list of Jordan cells of current matrix.\n        This list shape Jordan matrix J.\n\n        If calc_transformation is specified as False, then transformation P such that\n\n              `J = P^{-1} \\cdot M \\cdot P`\n\n        will not be calculated.\n\n        Notes\n        =====\n\n        Calculation of transformation P is not implemented yet.\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix\n        >>> m = Matrix(4, 4, [\n        ...  6,  5, -2, -3,\n        ... -3, -1,  3,  3,\n        ...  2,  1, -2, -3,\n        ... -1,  1,  5,  5])\n\n        >>> P, Jcells = m.jordan_cells()\n        >>> Jcells[0]\n        Matrix([\n        [2, 1],\n        [0, 2]])\n        >>> Jcells[1]\n        Matrix([\n        [2, 1],\n        [0, 2]])\n\n        See Also\n        ========\n\n        jordan_form\n        \"\"\"\n        n = self.rows\n        Jcells = []\n        Pcols_new = []\n        jordan_block_structures = self._jordan_block_structure()\n        from sympy.matrices import MutableMatrix\n\n        # Order according to default_sort_key, this makes sure the order is the same as in .diagonalize():\n        for eigenval in (\n        sorted(list(jordan_block_structures.keys()), key=default_sort_key)):\n            l_jordan_chains = jordan_block_structures[eigenval]\n            for s in reversed(sorted(\n                    (l_jordan_chains).keys())):  # Start with the biggest block\n                s_chains = l_jordan_chains[s]\n                block = self.jordan_cell(eigenval, s)\n                number_of_s_chains = len(s_chains)\n                for i in range(0, number_of_s_chains):\n                    Jcells.append(type(self)(block))\n                    chain_vectors = s_chains[i]\n                    lc = len(chain_vectors)\n                    assert lc == s\n                    for j in range(0, lc):\n                        generalized_eigen_vector = chain_vectors[j]\n                        Pcols_new.append(generalized_eigen_vector)\n        P = MutableMatrix.zeros(n)\n        for j in range(0, n):\n            P[:, j] = Pcols_new[j]\n\n        return type(self)(P), Jcells\n\n    def jordan_form(self, calc_transformation=True):\n        r\"\"\"Return Jordan form J of current matrix.\n\n        Also the transformation P such that\n\n            `J = P^{-1} \\cdot M \\cdot P`\n\n        and the jordan blocks forming J\n        will be calculated.\n\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix\n        >>> m = Matrix([\n        ...        [ 6,  5, -2, -3],\n        ...        [-3, -1,  3,  3],\n        ...        [ 2,  1, -2, -3],\n        ...        [-1,  1,  5,  5]])\n        >>> P, J = m.jordan_form()\n        >>> J\n        Matrix([\n        [2, 1, 0, 0],\n        [0, 2, 0, 0],\n        [0, 0, 2, 1],\n        [0, 0, 0, 2]])\n\n        See Also\n        ========\n\n        jordan_cells\n        \"\"\"\n        P, Jcells = self.jordan_cells()\n        from sympy.matrices import diag\n        J = diag(*Jcells)\n        return P, type(self)(J)\n\n    def key2bounds(self, keys):\n        \"\"\"Converts a key with potentially mixed types of keys (integer and slice)\n        into a tuple of ranges and raises an error if any index is out of self's\n        range.\n\n        See Also\n        ========\n\n        key2ij\n        \"\"\"\n\n        islice, jslice = [isinstance(k, slice) for k in keys]\n        if islice:\n            if not self.rows:\n                rlo = rhi = 0\n            else:\n                rlo, rhi = keys[0].indices(self.rows)[:2]\n        else:\n            rlo = a2idx(keys[0], self.rows)\n            rhi = rlo + 1\n        if jslice:\n            if not self.cols:\n                clo = chi = 0\n            else:\n                clo, chi = keys[1].indices(self.cols)[:2]\n        else:\n            clo = a2idx(keys[1], self.cols)\n            chi = clo + 1\n        return rlo, rhi, clo, chi\n\n    def key2ij(self, key):\n        \"\"\"Converts key into canonical form, converting integers or indexable\n        items into valid integers for self's range or returning slices\n        unchanged.\n\n        See Also\n        ========\n\n        key2bounds\n        \"\"\"\n        if is_sequence(key):\n            if not len(key) == 2:\n                raise TypeError('key must be a sequence of length 2')\n            return [a2idx(i, n) if not isinstance(i, slice) else i\n                    for i, n in zip(key, self.shape)]\n        elif isinstance(key, slice):\n            return key.indices(len(self))[:2]\n        else:\n            return divmod(a2idx(key, len(self)), self.cols)\n\n    def LDLdecomposition(self):\n        \"\"\"Returns the LDL Decomposition (L, D) of matrix A,\n        such that L * D * L.T == A\n        This method eliminates the use of square root.\n        Further this ensures that all the diagonal entries of L are 1.\n        A must be a square, symmetric, positive-definite\n        and non-singular matrix.\n\n        Examples\n        ========\n\n        >>> from sympy.matrices import Matrix, eye\n        >>> A = Matrix(((25, 15, -5), (15, 18, 0), (-5, 0, 11)))\n        >>> L, D = A.LDLdecomposition()\n        >>> L\n        Matrix([\n        [   1,   0, 0],\n        [ 3/5,   1, 0],\n        [-1/5, 1/3, 1]])\n        >>> D\n        Matrix([\n        [25, 0, 0],\n        [ 0, 9, 0],\n        [ 0, 0, 9]])\n        >>> L * D * L.T * A.inv() == eye(A.rows)\n        True\n\n        See Also\n        ========\n\n        cholesky\n        LUdecomposition\n        QRdecomposition\n        \"\"\"\n        if not self.is_square:\n            raise NonSquareMatrixError(\"Matrix must be square.\")\n        if not self.is_symmetric():\n            raise ValueError(\"Matrix must be symmetric.\")\n        return self._LDLdecomposition()\n\n    def LDLsolve(self, rhs):\n        \"\"\"Solves Ax = B using LDL decomposition,\n        for a general square and non-singular matrix.\n\n        For a non-square matrix with rows > cols,\n        the least squares solution is returned.\n\n        Examples\n        ========\n\n        >>> from sympy.matrices import Matrix, eye\n        >>> A = eye(2)*2\n        >>> B = Matrix([[1, 2], [3, 4]])\n        >>> A.LDLsolve(B) == B/2\n        True\n\n        See Also\n        ========\n\n        LDLdecomposition\n        lower_triangular_solve\n        upper_triangular_solve\n        gauss_jordan_solve\n        cholesky_solve\n        diagonal_solve\n        LUsolve\n        QRsolve\n        pinv_solve\n        \"\"\"\n        if self.is_symmetric():\n            L, D = self.LDLdecomposition()\n        elif self.rows >= self.cols:\n            L, D = (self.T * self).LDLdecomposition()\n            rhs = self.T * rhs\n        else:\n            raise NotImplementedError('Under-determined System. '\n                                      'Try M.gauss_jordan_solve(rhs)')\n        Y = L._lower_triangular_solve(rhs)\n        Z = D._diagonal_solve(Y)\n        return (L.T)._upper_triangular_solve(Z)\n\n    def left_eigenvects(self, **flags):\n        \"\"\"Returns left eigenvectors and eigenvalues.\n\n        This function returns the list of triples (eigenval, multiplicity,\n        basis) for the left eigenvectors. Options are the same as for\n        eigenvects(), i.e. the ``**flags`` arguments gets passed directly to\n        eigenvects().\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix\n        >>> M = Matrix([[0, 1, 1], [1, 0, 0], [1, 1, 1]])\n        >>> M.eigenvects()\n        [(-1, 1, [Matrix([\n        [-1],\n        [ 1],\n        [ 0]])]), (0, 1, [Matrix([\n        [ 0],\n        [-1],\n        [ 1]])]), (2, 1, [Matrix([\n        [2/3],\n        [1/3],\n        [  1]])])]\n        >>> M.left_eigenvects()\n        [(-1, 1, [Matrix([[-2, 1, 1]])]), (0, 1, [Matrix([[-1, -1, 1]])]), (2,\n        1, [Matrix([[1, 1, 1]])])]\n\n        \"\"\"\n        mat = self\n        left_transpose = mat.transpose().eigenvects(**flags)\n\n        left = []\n        for (ev, mult, ltmp) in left_transpose:\n            left.append((ev, mult, [l.transpose() for l in ltmp]))\n\n        return left\n\n    def limit(self, *args):\n        \"\"\"Calculate the limit of each element in the matrix.\n\n        Examples\n        ========\n\n        >>> from sympy.matrices import Matrix\n        >>> from sympy.abc import x, y\n        >>> M = Matrix([[x, y], [1, 0]])\n        >>> M.limit(x, 2)\n        Matrix([\n        [2, y],\n        [1, 0]])\n\n        See Also\n        ========\n\n        integrate\n        diff\n        \"\"\"\n        return self._new(self.rows, self.cols,\n                         lambda i, j: self[i, j].limit(*args))\n\n    def lower_triangular_solve(self, rhs):\n        \"\"\"Solves Ax = B, where A is a lower triangular matrix.\n\n        See Also\n        ========\n\n        upper_triangular_solve\n        gauss_jordan_solve\n        cholesky_solve\n        diagonal_solve\n        LDLsolve\n        LUsolve\n        QRsolve\n        pinv_solve\n        \"\"\"\n\n        if not self.is_square:\n            raise NonSquareMatrixError(\"Matrix must be square.\")\n        if rhs.rows != self.rows:\n            raise ShapeError(\"Matrices size mismatch.\")\n        if not self.is_lower:\n            raise ValueError(\"Matrix must be lower triangular.\")\n        return self._lower_triangular_solve(rhs)\n\n    def LUdecomposition(self, iszerofunc=_iszero):\n        \"\"\"Returns the decomposition LU and the row swaps p.\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix\n        >>> a = Matrix([[4, 3], [6, 3]])\n        >>> L, U, _ = a.LUdecomposition()\n        >>> L\n        Matrix([\n        [  1, 0],\n        [3/2, 1]])\n        >>> U\n        Matrix([\n        [4,    3],\n        [0, -3/2]])\n\n        See Also\n        ========\n\n        cholesky\n        LDLdecomposition\n        QRdecomposition\n        LUdecomposition_Simple\n        LUdecompositionFF\n        LUsolve\n        \"\"\"\n        combined, p = self.LUdecomposition_Simple(iszerofunc=_iszero)\n        L = self.zeros(self.rows)\n        U = self.zeros(self.rows)\n        for i in range(self.rows):\n            for j in range(self.rows):\n                if i > j:\n                    L[i, j] = combined[i, j]\n                else:\n                    if i == j:\n                        L[i, i] = 1\n                    U[i, j] = combined[i, j]\n        return L, U, p\n\n    def LUdecomposition_Simple(self, iszerofunc=_iszero):\n        \"\"\"Returns A comprised of L, U (L's diag entries are 1) and\n        p which is the list of the row swaps (in order).\n\n        See Also\n        ========\n\n        LUdecomposition\n        LUdecompositionFF\n        LUsolve\n        \"\"\"\n        if not self.is_square:\n            raise NonSquareMatrixError(\n                \"A Matrix must be square to apply LUdecomposition_Simple().\")\n        n = self.rows\n        A = self.as_mutable()\n        p = []\n        # factorization\n        for j in range(n):\n            for i in range(j):\n                for k in range(i):\n                    A[i, j] = A[i, j] - A[i, k] * A[k, j]\n            pivot = -1\n            for i in range(j, n):\n                for k in range(j):\n                    A[i, j] = A[i, j] - A[i, k] * A[k, j]\n                # find the first non-zero pivot, includes any expression\n                if pivot == -1 and not iszerofunc(A[i, j]):\n                    pivot = i\n            if pivot < 0:\n                # this result is based on iszerofunc's analysis of the possible pivots, so even though\n                # the element may not be strictly zero, the supplied iszerofunc's evaluation gave True\n                raise ValueError(\"No nonzero pivot found; inversion failed.\")\n            if pivot != j:  # row must be swapped\n                A.row_swap(pivot, j)\n                p.append([pivot, j])\n            scale = 1 / A[j, j]\n            for i in range(j + 1, n):\n                A[i, j] = A[i, j] * scale\n        return A, p\n\n    def LUdecompositionFF(self):\n        \"\"\"Compute a fraction-free LU decomposition.\n\n        Returns 4 matrices P, L, D, U such that PA = L D**-1 U.\n        If the elements of the matrix belong to some integral domain I, then all\n        elements of L, D and U are guaranteed to belong to I.\n\n        **Reference**\n            - W. Zhou & D.J. Jeffrey, \"Fraction-free matrix factors: new forms\n              for LU and QR factors\". Frontiers in Computer Science in China,\n              Vol 2, no. 1, pp. 67-80, 2008.\n\n        See Also\n        ========\n\n        LUdecomposition\n        LUdecomposition_Simple\n        LUsolve\n        \"\"\"\n        from sympy.matrices import SparseMatrix\n        zeros = SparseMatrix.zeros\n        eye = SparseMatrix.eye\n\n        n, m = self.rows, self.cols\n        U, L, P = self.as_mutable(), eye(n), eye(n)\n        DD = zeros(n, n)\n        oldpivot = 1\n\n        for k in range(n - 1):\n            if U[k, k] == 0:\n                for kpivot in range(k + 1, n):\n                    if U[kpivot, k]:\n                        break\n                else:\n                    raise ValueError(\"Matrix is not full rank\")\n                U[k, k:], U[kpivot, k:] = U[kpivot, k:], U[k, k:]\n                L[k, :k], L[kpivot, :k] = L[kpivot, :k], L[k, :k]\n                P[k, :], P[kpivot, :] = P[kpivot, :], P[k, :]\n            L[k, k] = Ukk = U[k, k]\n            DD[k, k] = oldpivot * Ukk\n            for i in range(k + 1, n):\n                L[i, k] = Uik = U[i, k]\n                for j in range(k + 1, m):\n                    U[i, j] = (Ukk * U[i, j] - U[k, j] * Uik) / oldpivot\n                U[i, k] = 0\n            oldpivot = Ukk\n        DD[n - 1, n - 1] = oldpivot\n        return P, L, DD, U\n\n    def LUsolve(self, rhs, iszerofunc=_iszero):\n        \"\"\"Solve the linear system Ax = rhs for x where A = self.\n\n        This is for symbolic matrices, for real or complex ones use\n        mpmath.lu_solve or mpmath.qr_solve.\n\n        See Also\n        ========\n\n        lower_triangular_solve\n        upper_triangular_solve\n        gauss_jordan_solve\n        cholesky_solve\n        diagonal_solve\n        LDLsolve\n        QRsolve\n        pinv_solve\n        LUdecomposition\n        \"\"\"\n        if rhs.rows != self.rows:\n            raise ShapeError(\n                \"`self` and `rhs` must have the same number of rows.\")\n\n        A, perm = self.LUdecomposition_Simple(iszerofunc=_iszero)\n        n = self.rows\n        b = rhs.permuteFwd(perm).as_mutable()\n        # forward substitution, all diag entries are scaled to 1\n        for i in range(n):\n            for j in range(i):\n                scale = A[i, j]\n                b.zip_row_op(i, j, lambda x, y: x - y * scale)\n        # backward substitution\n        for i in range(n - 1, -1, -1):\n            for j in range(i + 1, n):\n                scale = A[i, j]\n                b.zip_row_op(i, j, lambda x, y: x - y * scale)\n            scale = A[i, i]\n            b.row_op(i, lambda x, _: x / scale)\n        return rhs.__class__(b)\n\n    def minorEntry(self, i, j, method=\"berkowitz\"):\n        return self.minor(i, j, method=method)\n\n    def minorMatrix(self, i, j):\n        return self.minor_submatrix(i, j)\n\n    def multiply(self, b):\n        \"\"\"Returns self*b\n\n        See Also\n        ========\n\n        dot\n        cross\n        multiply_elementwise\n        \"\"\"\n        return self * b\n\n    def normalized(self):\n        \"\"\"Return the normalized version of ``self``.\n\n        See Also\n        ========\n\n        norm\n        \"\"\"\n        if self.rows != 1 and self.cols != 1:\n            raise ShapeError(\"A Matrix must be a vector to normalize.\")\n        norm = self.norm()\n        out = self.applyfunc(lambda i: i / norm)\n        return out\n\n    def norm(self, ord=None):\n        \"\"\"Return the Norm of a Matrix or Vector.\n        In the simplest case this is the geometric size of the vector\n        Other norms can be specified by the ord parameter\n\n\n        =====  ============================  ==========================\n        ord    norm for matrices             norm for vectors\n        =====  ============================  ==========================\n        None   Frobenius norm                2-norm\n        'fro'  Frobenius norm                - does not exist\n        inf    --                            max(abs(x))\n        -inf   --                            min(abs(x))\n        1      --                            as below\n        -1     --                            as below\n        2      2-norm (largest sing. value)  as below\n        -2     smallest singular value       as below\n        other  - does not exist              sum(abs(x)**ord)**(1./ord)\n        =====  ============================  ==========================\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix, Symbol, trigsimp, cos, sin, oo\n        >>> x = Symbol('x', real=True)\n        >>> v = Matrix([cos(x), sin(x)])\n        >>> trigsimp( v.norm() )\n        1\n        >>> v.norm(10)\n        (sin(x)**10 + cos(x)**10)**(1/10)\n        >>> A = Matrix([[1, 1], [1, 1]])\n        >>> A.norm(2)# Spectral norm (max of |Ax|/|x| under 2-vector-norm)\n        2\n        >>> A.norm(-2) # Inverse spectral norm (smallest singular value)\n        0\n        >>> A.norm() # Frobenius Norm\n        2\n        >>> Matrix([1, -2]).norm(oo)\n        2\n        >>> Matrix([-1, 2]).norm(-oo)\n        1\n\n        See Also\n        ========\n\n        normalized\n        \"\"\"\n        # Row or Column Vector Norms\n        vals = list(self.values()) or [0]\n        if self.rows == 1 or self.cols == 1:\n            if ord == 2 or ord is None:  # Common case sqrt(<x, x>)\n                return sqrt(Add(*(abs(i) ** 2 for i in vals)))\n\n            elif ord == 1:  # sum(abs(x))\n                return Add(*(abs(i) for i in vals))\n\n            elif ord == S.Infinity:  # max(abs(x))\n                return Max(*[abs(i) for i in vals])\n\n            elif ord == S.NegativeInfinity:  # min(abs(x))\n                return Min(*[abs(i) for i in vals])\n\n            # Otherwise generalize the 2-norm, Sum(x_i**ord)**(1/ord)\n            # Note that while useful this is not mathematically a norm\n            try:\n                return Pow(Add(*(abs(i) ** ord for i in vals)), S(1) / ord)\n            except (NotImplementedError, TypeError):\n                raise ValueError(\"Expected order to be Number, Symbol, oo\")\n\n        # Matrix Norms\n        else:\n            if ord == 2:  # Spectral Norm\n                # Maximum singular value\n                return Max(*self.singular_values())\n\n            elif ord == -2:\n                # Minimum singular value\n                return Min(*self.singular_values())\n\n            elif (ord is None or isinstance(ord,\n                                            string_types) and ord.lower() in\n                ['f', 'fro', 'frobenius', 'vector']):\n                # Reshape as vector and send back to norm function\n                return self.vec().norm(ord=2)\n\n            else:\n                raise NotImplementedError(\"Matrix Norms under development\")\n\n    def nullspace(self, simplify=False):\n        \"\"\"Returns list of vectors (Matrix objects) that span nullspace of self\n\n        Examples\n        ========\n\n        >>> from sympy.matrices import Matrix\n        >>> m = Matrix(3, 3, [1, 3, 0, -2, -6, 0, 3, 9, 6])\n        >>> m\n        Matrix([\n        [ 1,  3, 0],\n        [-2, -6, 0],\n        [ 3,  9, 6]])\n        >>> m.nullspace()\n        [Matrix([\n        [-3],\n        [ 1],\n        [ 0]])]\n\n        See Also\n        ========\n\n        columnspace\n        \"\"\"\n        from sympy.matrices import zeros\n\n        simpfunc = simplify if isinstance(\n            simplify, FunctionType) else _simplify\n        reduced, pivots = self.rref(simplify=simpfunc)\n\n        basis = []\n        # create a set of vectors for the basis\n        for i in range(self.cols - len(pivots)):\n            basis.append(zeros(self.cols, 1))\n        # contains the variable index to which the vector corresponds\n        basiskey, cur = [-1] * len(basis), 0\n        for i in range(self.cols):\n            if i not in pivots:\n                basiskey[cur] = i\n                cur += 1\n        for i in range(self.cols):\n            if i not in pivots:  # free var, just set vector's ith place to 1\n                basis[basiskey.index(i)][i, 0] = 1\n            else:  # add negative of nonpivot entry to corr vector\n                for j in range(i + 1, self.cols):\n                    line = pivots.index(i)\n                    v = reduced[line, j]\n                    if simplify:\n                        v = simpfunc(v)\n                    if v:\n                        if j in pivots:\n                            # XXX: Is this the correct error?\n                            raise NotImplementedError(\n                                \"Could not compute the nullspace of `self`.\")\n                        basis[basiskey.index(j)][i, 0] = -v\n        return [self._new(b) for b in basis]\n\n    def permuteBkwd(self, perm):\n        \"\"\"Permute the rows of the matrix with the given permutation in reverse.\n\n        Examples\n        ========\n\n        >>> from sympy.matrices import eye\n        >>> M = eye(3)\n        >>> M.permuteBkwd([[0, 1], [0, 2]])\n        Matrix([\n        [0, 1, 0],\n        [0, 0, 1],\n        [1, 0, 0]])\n\n        See Also\n        ========\n\n        permuteFwd\n        \"\"\"\n        copy = self.copy()\n        for i in range(len(perm) - 1, -1, -1):\n            copy.row_swap(perm[i][0], perm[i][1])\n        return copy\n\n    def permuteFwd(self, perm):\n        \"\"\"Permute the rows of the matrix with the given permutation.\n\n        Examples\n        ========\n\n        >>> from sympy.matrices import eye\n        >>> M = eye(3)\n        >>> M.permuteFwd([[0, 1], [0, 2]])\n        Matrix([\n        [0, 0, 1],\n        [1, 0, 0],\n        [0, 1, 0]])\n\n        See Also\n        ========\n\n        permuteBkwd\n        \"\"\"\n        copy = self.copy()\n        for i in range(len(perm)):\n            copy.row_swap(perm[i][0], perm[i][1])\n        return copy\n\n    def pinv_solve(self, B, arbitrary_matrix=None):\n        \"\"\"Solve Ax = B using the Moore-Penrose pseudoinverse.\n\n        There may be zero, one, or infinite solutions.  If one solution\n        exists, it will be returned.  If infinite solutions exist, one will\n        be returned based on the value of arbitrary_matrix.  If no solutions\n        exist, the least-squares solution is returned.\n\n        Parameters\n        ==========\n\n        B : Matrix\n            The right hand side of the equation to be solved for.  Must have\n            the same number of rows as matrix A.\n        arbitrary_matrix : Matrix\n            If the system is underdetermined (e.g. A has more columns than\n            rows), infinite solutions are possible, in terms of an arbitrary\n            matrix.  This parameter may be set to a specific matrix to use\n            for that purpose; if so, it must be the same shape as x, with as\n            many rows as matrix A has columns, and as many columns as matrix\n            B.  If left as None, an appropriate matrix containing dummy\n            symbols in the form of ``wn_m`` will be used, with n and m being\n            row and column position of each symbol.\n\n        Returns\n        =======\n\n        x : Matrix\n            The matrix that will satisfy Ax = B.  Will have as many rows as\n            matrix A has columns, and as many columns as matrix B.\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix\n        >>> A = Matrix([[1, 2, 3], [4, 5, 6]])\n        >>> B = Matrix([7, 8])\n        >>> A.pinv_solve(B)\n        Matrix([\n        [ _w0_0/6 - _w1_0/3 + _w2_0/6 - 55/18],\n        [-_w0_0/3 + 2*_w1_0/3 - _w2_0/3 + 1/9],\n        [ _w0_0/6 - _w1_0/3 + _w2_0/6 + 59/18]])\n        >>> A.pinv_solve(B, arbitrary_matrix=Matrix([0, 0, 0]))\n        Matrix([\n        [-55/18],\n        [   1/9],\n        [ 59/18]])\n\n        See Also\n        ========\n\n        lower_triangular_solve\n        upper_triangular_solve\n        gauss_jordan_solve\n        cholesky_solve\n        diagonal_solve\n        LDLsolve\n        LUsolve\n        QRsolve\n        pinv\n\n        Notes\n        =====\n\n        This may return either exact solutions or least squares solutions.\n        To determine which, check ``A * A.pinv() * B == B``.  It will be\n        True if exact solutions exist, and False if only a least-squares\n        solution exists.  Be aware that the left hand side of that equation\n        may need to be simplified to correctly compare to the right hand\n        side.\n\n        References\n        ==========\n\n        .. [1] https://en.wikipedia.org/wiki/Moore-Penrose_pseudoinverse#Obtaining_all_solutions_of_a_linear_system\n\n        \"\"\"\n        from sympy.matrices import eye\n        A = self\n        A_pinv = self.pinv()\n        if arbitrary_matrix is None:\n            rows, cols = A.cols, B.cols\n            w = symbols('w:{0}_:{1}'.format(rows, cols), cls=Dummy)\n            arbitrary_matrix = self.__class__(cols, rows, w).T\n        return A_pinv * B + (eye(A.cols) - A_pinv * A) * arbitrary_matrix\n\n    def pinv(self):\n        \"\"\"Calculate the Moore-Penrose pseudoinverse of the matrix.\n\n        The Moore-Penrose pseudoinverse exists and is unique for any matrix.\n        If the matrix is invertible, the pseudoinverse is the same as the\n        inverse.\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix\n        >>> Matrix([[1, 2, 3], [4, 5, 6]]).pinv()\n        Matrix([\n        [-17/18,  4/9],\n        [  -1/9,  1/9],\n        [ 13/18, -2/9]])\n\n        See Also\n        ========\n\n        inv\n        pinv_solve\n\n        References\n        ==========\n\n        .. [1] https://en.wikipedia.org/wiki/Moore-Penrose_pseudoinverse\n\n        \"\"\"\n        A = self\n        AH = self.H\n        # Trivial case: pseudoinverse of all-zero matrix is its transpose.\n        if A.is_zero:\n            return AH\n        try:\n            if self.rows >= self.cols:\n                return (AH * A).inv() * AH\n            else:\n                return AH * (A * AH).inv()\n        except ValueError:\n            # Matrix is not full rank, so A*AH cannot be inverted.\n            raise NotImplementedError('Rank-deficient matrices are not yet '\n                                      'supported.')\n\n    def print_nonzero(self, symb=\"X\"):\n        \"\"\"Shows location of non-zero entries for fast shape lookup.\n\n        Examples\n        ========\n\n        >>> from sympy.matrices import Matrix, eye\n        >>> m = Matrix(2, 3, lambda i, j: i*3+j)\n        >>> m\n        Matrix([\n        [0, 1, 2],\n        [3, 4, 5]])\n        >>> m.print_nonzero()\n        [ XX]\n        [XXX]\n        >>> m = eye(4)\n        >>> m.print_nonzero(\"x\")\n        [x   ]\n        [ x  ]\n        [  x ]\n        [   x]\n\n        \"\"\"\n        s = []\n        for i in range(self.rows):\n            line = []\n            for j in range(self.cols):\n                if self[i, j] == 0:\n                    line.append(\" \")\n                else:\n                    line.append(str(symb))\n            s.append(\"[%s]\" % ''.join(line))\n        print('\\n'.join(s))\n\n    def project(self, v):\n        \"\"\"Return the projection of ``self`` onto the line containing ``v``.\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix, S, sqrt\n        >>> V = Matrix([sqrt(3)/2, S.Half])\n        >>> x = Matrix([[1, 0]])\n        >>> V.project(x)\n        Matrix([[sqrt(3)/2, 0]])\n        >>> V.project(-x)\n        Matrix([[sqrt(3)/2, 0]])\n        \"\"\"\n        return v * (self.dot(v) / v.dot(v))\n\n    def QRdecomposition(self):\n        \"\"\"Return Q, R where A = Q*R, Q is orthogonal and R is upper triangular.\n\n        Examples\n        ========\n\n        This is the example from wikipedia:\n\n        >>> from sympy import Matrix\n        >>> A = Matrix([[12, -51, 4], [6, 167, -68], [-4, 24, -41]])\n        >>> Q, R = A.QRdecomposition()\n        >>> Q\n        Matrix([\n        [ 6/7, -69/175, -58/175],\n        [ 3/7, 158/175,   6/175],\n        [-2/7,    6/35,  -33/35]])\n        >>> R\n        Matrix([\n        [14,  21, -14],\n        [ 0, 175, -70],\n        [ 0,   0,  35]])\n        >>> A == Q*R\n        True\n\n        QR factorization of an identity matrix:\n\n        >>> A = Matrix([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n        >>> Q, R = A.QRdecomposition()\n        >>> Q\n        Matrix([\n        [1, 0, 0],\n        [0, 1, 0],\n        [0, 0, 1]])\n        >>> R\n        Matrix([\n        [1, 0, 0],\n        [0, 1, 0],\n        [0, 0, 1]])\n\n        See Also\n        ========\n\n        cholesky\n        LDLdecomposition\n        LUdecomposition\n        QRsolve\n        \"\"\"\n        cls = self.__class__\n        mat = self.as_mutable()\n\n        if not mat.rows >= mat.cols:\n            raise MatrixError(\n                \"The number of rows must be greater than columns\")\n        n = mat.rows\n        m = mat.cols\n        rank = n\n        row_reduced = mat.rref()[0]\n        for i in range(row_reduced.rows):\n            if row_reduced.row(i).norm() == 0:\n                rank -= 1\n        if not rank == mat.cols:\n            raise MatrixError(\"The rank of the matrix must match the columns\")\n        Q, R = mat.zeros(n, m), mat.zeros(m)\n        for j in range(m):  # for each column vector\n            tmp = mat[:, j]  # take original v\n            for i in range(j):\n                # subtract the project of mat on new vector\n                tmp -= Q[:, i] * mat[:, j].dot(Q[:, i])\n                tmp.expand()\n            # normalize it\n            R[j, j] = tmp.norm()\n            Q[:, j] = tmp / R[j, j]\n            if Q[:, j].norm() != 1:\n                raise NotImplementedError(\n                    \"Could not normalize the vector %d.\" % j)\n            for i in range(j):\n                R[i, j] = Q[:, i].dot(mat[:, j])\n        return cls(Q), cls(R)\n\n    def QRsolve(self, b):\n        \"\"\"Solve the linear system 'Ax = b'.\n\n        'self' is the matrix 'A', the method argument is the vector\n        'b'.  The method returns the solution vector 'x'.  If 'b' is a\n        matrix, the system is solved for each column of 'b' and the\n        return value is a matrix of the same shape as 'b'.\n\n        This method is slower (approximately by a factor of 2) but\n        more stable for floating-point arithmetic than the LUsolve method.\n        However, LUsolve usually uses an exact arithmetic, so you don't need\n        to use QRsolve.\n\n        This is mainly for educational purposes and symbolic matrices, for real\n        (or complex) matrices use mpmath.qr_solve.\n\n        See Also\n        ========\n\n        lower_triangular_solve\n        upper_triangular_solve\n        gauss_jordan_solve\n        cholesky_solve\n        diagonal_solve\n        LDLsolve\n        LUsolve\n        pinv_solve\n        QRdecomposition\n        \"\"\"\n\n        Q, R = self.as_mutable().QRdecomposition()\n        y = Q.T * b\n\n        # back substitution to solve R*x = y:\n        # We build up the result \"backwards\" in the vector 'x' and reverse it\n        # only in the end.\n        x = []\n        n = R.rows\n        for j in range(n - 1, -1, -1):\n            tmp = y[j, :]\n            for k in range(j + 1, n):\n                tmp -= R[j, k] * x[n - 1 - k]\n            x.append(tmp / R[j, j])\n        return self._new([row._mat for row in reversed(x)])\n\n    def rank(self, iszerofunc=_iszero, simplify=False):\n        \"\"\"\n        Returns the rank of a matrix\n\n        >>> from sympy import Matrix\n        >>> from sympy.abc import x\n        >>> m = Matrix([[1, 2], [x, 1 - 1/x]])\n        >>> m.rank()\n        2\n        >>> n = Matrix(3, 3, range(1, 10))\n        >>> n.rank()\n        2\n        \"\"\"\n        row_reduced = self.rref(iszerofunc=iszerofunc, simplify=simplify)\n        rank = len(row_reduced[-1])\n        return rank\n\n    def rref(self, iszerofunc=_iszero, simplify=False):\n        \"\"\"Return reduced row-echelon form of matrix and indices of pivot vars.\n\n        To simplify elements before finding nonzero pivots set simplify=True\n        (to use the default SymPy simplify function) or pass a custom\n        simplify function.\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix\n        >>> from sympy.abc import x\n        >>> m = Matrix([[1, 2], [x, 1 - 1/x]])\n        >>> m.rref()\n        (Matrix([\n        [1, 0],\n        [0, 1]]), [0, 1])\n        >>> rref_matrix, rref_pivots = m.rref()\n        >>> rref_matrix\n        Matrix([\n        [1, 0],\n        [0, 1]])\n        >>> rref_pivots\n        [0, 1]\n        \"\"\"\n        simpfunc = simplify if isinstance(\n            simplify, FunctionType) else _simplify\n        # pivot: index of next row to contain a pivot\n        pivot, r = 0, self.as_mutable()\n        # pivotlist: indices of pivot variables (non-free)\n        pivotlist = []\n        for i in range(r.cols):\n            if pivot == r.rows:\n                break\n            if simplify:\n                r[pivot, i] = simpfunc(r[pivot, i])\n\n            pivot_offset, pivot_val, assumed_nonzero, newly_determined = _find_reasonable_pivot(\n                r[pivot:, i], iszerofunc, simpfunc)\n            # `_find_reasonable_pivot` may have simplified\n            # some elements along the way.  If they were simplified\n            # and then determined to be either zero or non-zero for\n            # sure, they are stored in the `newly_determined` list\n            for (offset, val) in newly_determined:\n                r[pivot + offset, i] = val\n\n            # if `pivot_offset` is None, this column has no\n            # pivot\n            if pivot_offset is None:\n                continue\n\n            # swap the pivot column into place\n            pivot_pos = pivot + pivot_offset\n            r.row_swap(pivot, pivot_pos)\n\n            r.row_op(pivot, lambda x, _: x / pivot_val)\n            for j in range(r.rows):\n                if j == pivot:\n                    continue\n                pivot_val = r[j, i]\n                r.zip_row_op(j, pivot, lambda x, y: x - pivot_val * y)\n            pivotlist.append(i)\n            pivot += 1\n        return self._new(r), pivotlist\n\n    def singular_values(self):\n        \"\"\"Compute the singular values of a Matrix\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix, Symbol\n        >>> x = Symbol('x', real=True)\n        >>> A = Matrix([[0, 1, 0], [0, x, 0], [-1, 0, 0]])\n        >>> A.singular_values()\n        [sqrt(x**2 + 1), 1, 0]\n\n        See Also\n        ========\n\n        condition_number\n        \"\"\"\n        mat = self.as_mutable()\n        # Compute eigenvalues of A.H A\n        valmultpairs = (mat.H * mat).eigenvals()\n\n        # Expands result from eigenvals into a simple list\n        vals = []\n        for k, v in valmultpairs.items():\n            vals += [sqrt(k)] * v  # dangerous! same k in several spots!\n        # sort them in descending order\n        vals.sort(reverse=True, key=default_sort_key)\n\n        return vals\n\n    def solve_least_squares(self, rhs, method='CH'):\n        \"\"\"Return the least-square fit to the data.\n\n        By default the cholesky_solve routine is used (method='CH'); other\n        methods of matrix inversion can be used. To find out which are\n        available, see the docstring of the .inv() method.\n\n        Examples\n        ========\n\n        >>> from sympy.matrices import Matrix, ones\n        >>> A = Matrix([1, 2, 3])\n        >>> B = Matrix([2, 3, 4])\n        >>> S = Matrix(A.row_join(B))\n        >>> S\n        Matrix([\n        [1, 2],\n        [2, 3],\n        [3, 4]])\n\n        If each line of S represent coefficients of Ax + By\n        and x and y are [2, 3] then S*xy is:\n\n        >>> r = S*Matrix([2, 3]); r\n        Matrix([\n        [ 8],\n        [13],\n        [18]])\n\n        But let's add 1 to the middle value and then solve for the\n        least-squares value of xy:\n\n        >>> xy = S.solve_least_squares(Matrix([8, 14, 18])); xy\n        Matrix([\n        [ 5/3],\n        [10/3]])\n\n        The error is given by S*xy - r:\n\n        >>> S*xy - r\n        Matrix([\n        [1/3],\n        [1/3],\n        [1/3]])\n        >>> _.norm().n(2)\n        0.58\n\n        If a different xy is used, the norm will be higher:\n\n        >>> xy += ones(2, 1)/10\n        >>> (S*xy - r).norm().n(2)\n        1.5\n\n        \"\"\"\n        if method == 'CH':\n            return self.cholesky_solve(rhs)\n        t = self.T\n        return (t * self).inv(method=method) * t * rhs\n\n    def solve(self, rhs, method='GE'):\n        \"\"\"Return solution to self*soln = rhs using given inversion method.\n\n        For a list of possible inversion methods, see the .inv() docstring.\n        \"\"\"\n\n        if not self.is_square:\n            if self.rows < self.cols:\n                raise ValueError('Under-determined system. '\n                                 'Try M.gauss_jordan_solve(rhs)')\n            elif self.rows > self.cols:\n                raise ValueError('For over-determined system, M, having '\n                                 'more rows than columns, try M.solve_least_squares(rhs).')\n        else:\n            return self.inv(method=method) * rhs\n\n    def table(self, printer, rowstart='[', rowend=']', rowsep='\\n',\n              colsep=', ', align='right'):\n        r\"\"\"\n        String form of Matrix as a table.\n\n        ``printer`` is the printer to use for on the elements (generally\n        something like StrPrinter())\n\n        ``rowstart`` is the string used to start each row (by default '[').\n\n        ``rowend`` is the string used to end each row (by default ']').\n\n        ``rowsep`` is the string used to separate rows (by default a newline).\n\n        ``colsep`` is the string used to separate columns (by default ', ').\n\n        ``align`` defines how the elements are aligned. Must be one of 'left',\n        'right', or 'center'.  You can also use '<', '>', and '^' to mean the\n        same thing, respectively.\n\n        This is used by the string printer for Matrix.\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix\n        >>> from sympy.printing.str import StrPrinter\n        >>> M = Matrix([[1, 2], [-33, 4]])\n        >>> printer = StrPrinter()\n        >>> M.table(printer)\n        '[  1, 2]\\n[-33, 4]'\n        >>> print(M.table(printer))\n        [  1, 2]\n        [-33, 4]\n        >>> print(M.table(printer, rowsep=',\\n'))\n        [  1, 2],\n        [-33, 4]\n        >>> print('[%s]' % M.table(printer, rowsep=',\\n'))\n        [[  1, 2],\n        [-33, 4]]\n        >>> print(M.table(printer, colsep=' '))\n        [  1 2]\n        [-33 4]\n        >>> print(M.table(printer, align='center'))\n        [ 1 , 2]\n        [-33, 4]\n        >>> print(M.table(printer, rowstart='{', rowend='}'))\n        {  1, 2}\n        {-33, 4}\n        \"\"\"\n        # Handle zero dimensions:\n        if self.rows == 0 or self.cols == 0:\n            return '[]'\n        # Build table of string representations of the elements\n        res = []\n        # Track per-column max lengths for pretty alignment\n        maxlen = [0] * self.cols\n        for i in range(self.rows):\n            res.append([])\n            for j in range(self.cols):\n                s = printer._print(self[i, j])\n                res[-1].append(s)\n                maxlen[j] = max(len(s), maxlen[j])\n        # Patch strings together\n        align = {\n            'left': 'ljust',\n            'right': 'rjust',\n            'center': 'center',\n            '<': 'ljust',\n            '>': 'rjust',\n            '^': 'center',\n        }[align]\n        for i, row in enumerate(res):\n            for j, elem in enumerate(row):\n                row[j] = getattr(elem, align)(maxlen[j])\n            res[i] = rowstart + colsep.join(row) + rowend\n        return rowsep.join(res)\n\n    def upper_triangular_solve(self, rhs):\n        \"\"\"Solves Ax = B, where A is an upper triangular matrix.\n\n        See Also\n        ========\n\n        lower_triangular_solve\n        gauss_jordan_solve\n        cholesky_solve\n        diagonal_solve\n        LDLsolve\n        LUsolve\n        QRsolve\n        pinv_solve\n        \"\"\"\n        if not self.is_square:\n            raise NonSquareMatrixError(\"Matrix must be square.\")\n        if rhs.rows != self.rows:\n            raise TypeError(\"Matrix size mismatch.\")\n        if not self.is_upper:\n            raise TypeError(\"Matrix is not upper triangular.\")\n        return self._upper_triangular_solve(rhs)\n\n    def vech(self, diagonal=True, check_symmetry=True):\n        \"\"\"Return the unique elements of a symmetric Matrix as a one column matrix\n        by stacking the elements in the lower triangle.\n\n        Arguments:\n        diagonal -- include the diagonal cells of self or not\n        check_symmetry -- checks symmetry of self but not completely reliably\n\n        Examples\n        ========\n\n        >>> from sympy import Matrix\n        >>> m=Matrix([[1, 2], [2, 3]])\n        >>> m\n        Matrix([\n        [1, 2],\n        [2, 3]])\n        >>> m.vech()\n        Matrix([\n        [1],\n        [2],\n        [3]])\n        >>> m.vech(diagonal=False)\n        Matrix([[2]])\n\n        See Also\n        ========\n\n        vec\n        \"\"\"\n        from sympy.matrices import zeros\n\n        c = self.cols\n        if c != self.rows:\n            raise ShapeError(\"Matrix must be square\")\n        if check_symmetry:\n            self.simplify()\n            if self != self.transpose():\n                raise ValueError(\n                    \"Matrix appears to be asymmetric; consider check_symmetry=False\")\n        count = 0\n        if diagonal:\n            v = zeros(c * (c + 1) // 2, 1)\n            for j in range(c):\n                for i in range(j, c):\n                    v[count] = self[i, j]\n                    count += 1\n        else:\n            v = zeros(c * (c - 1) // 2, 1)\n            for j in range(c):\n                for i in range(j + 1, c):\n                    v[count] = self[i, j]\n                    count += 1\n        return v\n\n\n    @classmethod\n    def vstack(cls, *args):\n        \"\"\"Return a matrix formed by joining args vertically (i.e.\n        by repeated application of col_join).\n\n        Examples\n        ========\n\n        >>> from sympy.matrices import Matrix, eye\n        >>> Matrix.vstack(eye(2), 2*eye(2))\n        Matrix([\n        [1, 0],\n        [0, 1],\n        [2, 0],\n        [0, 2]])\n        \"\"\"\n        kls = type(args[0])\n        return reduce(kls.col_join, args)\n\n\ndef classof(A, B):\n    \"\"\"\n    Get the type of the result when combining matrices of different types.\n\n    Currently the strategy is that immutability is contagious.\n\n    Examples\n    ========\n\n    >>> from sympy import Matrix, ImmutableMatrix\n    >>> from sympy.matrices.matrices import classof\n    >>> M = Matrix([[1, 2], [3, 4]]) # a Mutable Matrix\n    >>> IM = ImmutableMatrix([[1, 2], [3, 4]])\n    >>> classof(M, IM)\n    <class 'sympy.matrices.immutable.ImmutableDenseMatrix'>\n    \"\"\"\n    try:\n        if A._class_priority > B._class_priority:\n            return A.__class__\n        else:\n            return B.__class__\n    except Exception:\n        pass\n    try:\n        import numpy\n        if isinstance(A, numpy.ndarray):\n            return B.__class__\n        if isinstance(B, numpy.ndarray):\n            return A.__class__\n    except Exception:\n        pass\n    raise TypeError(\"Incompatible classes %s, %s\" % (A.__class__, B.__class__))\n\n\ndef a2idx(j, n=None):\n    \"\"\"Return integer after making positive and validating against n.\"\"\"\n    if type(j) is not int:\n        try:\n            j = j.__index__()\n        except AttributeError:\n            raise IndexError(\"Invalid index a[%r]\" % (j,))\n    if n is not None:\n        if j < 0:\n            j += n\n        if not (j >= 0 and j < n):\n            raise IndexError(\"Index out of range: a[%s]\" % (j,))\n    return int(j)\n\n\ndef _find_reasonable_pivot(col, iszerofunc=_iszero, simpfunc=_simplify):\n    \"\"\" Find the lowest index of an item in `col` that is\n    suitable for a pivot.  If `col` consists only of\n    Floats, the pivot with the largest norm is returned.\n    Otherwise, the first element where `iszerofunc` returns\n    False is used.  If `iszerofunc` doesn't return false,\n    items are simplified and retested until a suitable\n    pivot is found.\n\n    Returns a 4-tuple\n        (pivot_offset, pivot_val, assumed_nonzero, newly_determined)\n    where pivot_offset is the index of the pivot, pivot_val is\n    the (possibly simplified) value of the pivot, assumed_nonzero\n    is True if an assumption that the pivot was non-zero\n    was made without being proved, and newly_determined are\n    elements that were simplified during the process of pivot\n    finding.\"\"\"\n\n    newly_determined = []\n    col = list(col)\n    # a column that contains a mix of floats and integers\n    # but at least one float is considered a numerical\n    # column, and so we do partial pivoting\n    if all(isinstance(x, (Float, Integer)) for x in col) and any(\n            isinstance(x, Float) for x in col):\n        col_abs = [abs(x) for x in col]\n        max_value = max(col_abs)\n        if iszerofunc(max_value):\n            # just because iszerofunc returned True, doesn't\n            # mean the value is numerically zero.  Make sure\n            # to replace all entries with numerical zeros\n            if max_value != 0:\n                newly_determined = [(i, 0) for i, x in enumerate(col) if x != 0]\n            return (None, None, False, newly_determined)\n        index = col_abs.index(max_value)\n        return (index, col[index], False, newly_determined)\n\n    # PASS 1 (iszerofunc directly)\n    possible_zeros = []\n    for i, x in enumerate(col):\n        is_zero = iszerofunc(x)\n        # is someone wrote a custom iszerofunc, it may return\n        # BooleanFalse or BooleanTrue instead of True or False,\n        # so use == for comparison instead of `is`\n        if is_zero == False:\n            # we found something that is definitely not zero\n            return (i, x, False, newly_determined)\n        possible_zeros.append(is_zero)\n\n    # by this point, we've found no certain non-zeros\n    if all(possible_zeros):\n        # if everything is definitely zero, we have\n        # no pivot\n        return (None, None, False, newly_determined)\n\n    # PASS 2 (iszerofunc after simplify)\n    # we haven't found any for-sure non-zeros, so\n    # go through the elements iszerofunc couldn't\n    # make a determination about and opportunistically\n    # simplify to see if we find something\n    for i, x in enumerate(col):\n        if possible_zeros[i] is not None:\n            continue\n        simped = simpfunc(x)\n        is_zero = iszerofunc(simped)\n        if is_zero == True or is_zero == False:\n            newly_determined.append((i, simped))\n        if is_zero == False:\n            return (i, simped, False, newly_determined)\n        possible_zeros[i] = is_zero\n\n    # after simplifying, some things that were recognized\n    # as zeros might be zeros\n    if all(possible_zeros):\n        # if everything is definitely zero, we have\n        # no pivot\n        return (None, None, False, newly_determined)\n\n    # PASS 3 (.equals(0))\n    # some expressions fail to simplify to zero, but\n    # `.equals(0)` evaluates to True.  As a last-ditch\n    # attempt, apply `.equals` to these expressions\n    for i, x in enumerate(col):\n        if possible_zeros[i] is not None:\n            continue\n        if x.equals(S.Zero):\n            # `.iszero` may return False with\n            # an implicit assumption (e.g., `x.equals(0)`\n            # when `x` is a symbol), so only treat it\n            # as proved when `.equals(0)` returns True\n            possible_zeros[i] = True\n            newly_determined.append((i, S.Zero))\n\n    if all(possible_zeros):\n        return (None, None, False, newly_determined)\n\n    # at this point there is nothing that could definitely\n    # be a pivot.  To maintain compatibility with existing\n    # behavior, we'll assume that an illdetermined thing is\n    # non-zero.  We should probably raise a warning in this case\n    i = possible_zeros.index(None)\n    return (i, col[i], True, newly_determined)\n\n\nclass _MinimalMatrix(object):\n    \"\"\"Class providing the minimum functionality\n    for a matrix-like object and implementing every method\n    required for a `MatrixRequired`.  This class does not have everything\n    needed to become a full-fledged sympy object, but it will satisfy the\n    requirements of anything inheriting from `MatrixRequired`.  If you wish\n    to make a specialized matrix type, make sure to implement these\n    methods and properties with the exception of `__init__` and `__repr__`\n    which are included for convenience.\"\"\"\n\n    is_MatrixLike = True\n    _sympify = staticmethod(sympify)\n    _class_priority = 3\n\n    is_Matrix = True\n    is_MatrixExpr = False\n\n    @classmethod\n    def _new(cls, *args, **kwargs):\n        return cls(*args, **kwargs)\n\n    def __init__(self, rows, cols=None, mat=None):\n        if isinstance(mat, FunctionType):\n            # if we passed in a function, use that to populate the indices\n            mat = list(mat(i, j) for i in range(rows) for j in range(cols))\n        try:\n            if cols is None and mat is None:\n                mat = rows\n            rows, cols = mat.shape\n        except AttributeError:\n            pass\n        try:\n            # if we passed in a list of lists, flatten it and set the size\n            if cols is None and mat is None:\n                mat = rows\n            cols = len(mat[0])\n            rows = len(mat)\n            mat = [x for l in mat for x in l]\n        except (IndexError, TypeError):\n            pass\n        self.mat = tuple(self._sympify(x) for x in mat)\n        self.rows, self.cols = rows, cols\n        if self.rows is None or self.cols is None:\n            raise NotImplementedError(\"Cannot initialize matrix with given parameters\")\n\n    def __getitem__(self, key):\n        def _normalize_slices(row_slice, col_slice):\n            \"\"\"Ensure that row_slice and col_slice don't have\n            `None` in their arguments.  Any integers are converted\n            to slices of length 1\"\"\"\n            if not isinstance(row_slice, slice):\n                row_slice = slice(row_slice, row_slice + 1, None)\n            row_slice = slice(*row_slice.indices(self.rows))\n\n            if not isinstance(col_slice, slice):\n                col_slice = slice(col_slice, col_slice + 1, None)\n            col_slice = slice(*col_slice.indices(self.cols))\n\n            return (row_slice, col_slice)\n\n        def _coord_to_index(i, j):\n            \"\"\"Return the index in _mat corresponding\n            to the (i,j) position in the matrix. \"\"\"\n            return i * self.cols + j\n\n        if isinstance(key, tuple):\n            i, j = key\n            if isinstance(i, slice) or isinstance(j, slice):\n                # if the coordinates are not slices, make them so\n                # and expand the slices so they don't contain `None`\n                i, j = _normalize_slices(i, j)\n\n                rowsList, colsList = list(range(self.rows))[i], \\\n                                     list(range(self.cols))[j]\n                indices = (i * self.cols + j for i in rowsList for j in\n                           colsList)\n                return self._new(len(rowsList), len(colsList),\n                                 list(self.mat[i] for i in indices))\n\n            # if the key is a tuple of ints, change\n            # it to an array index\n            key = _coord_to_index(i, j)\n        return self.mat[key]\n\n    def __eq__(self, other):\n        return self.shape == other.shape and list(self) == list(other)\n\n    def __len__(self):\n        return self.rows*self.cols\n\n    def __repr__(self):\n        return \"_MinimalMatrix({}, {}, {})\".format(self.rows, self.cols,\n                                                   self.mat)\n\n    @property\n    def shape(self):\n        return (self.rows, self.cols)\n\n\nclass _MatrixWrapper(object):\n    \"\"\"Wrapper class providing the minimum functionality\n    for a matrix-like object: .rows, .cols, .shape, indexability,\n    and iterability.  CommonMatrix math operations should work\n    on matrix-like objects.  For example, wrapping a numpy\n    matrix in a MatrixWrapper allows it to be passed to CommonMatrix.\n    \"\"\"\n    is_MatrixLike = True\n\n    def __init__(self, mat, shape=None):\n        self.mat = mat\n        self.rows, self.cols = mat.shape if shape is None else shape\n\n    def __getattr__(self, attr):\n        \"\"\"Most attribute access is passed straight through\n        to the stored matrix\"\"\"\n        return getattr(self.mat, attr)\n\n    def __getitem__(self, key):\n        return self.mat.__getitem__(key)\n\n\ndef _matrixify(mat):\n    \"\"\"If `mat` is a Matrix or is matrix-like,\n    return a Matrix or MatrixWrapper object.  Otherwise\n    `mat` is passed through without modification.\"\"\"\n    if getattr(mat, 'is_Matrix', False):\n        return mat\n    if hasattr(mat, 'shape'):\n        if len(mat.shape) == 2:\n            return _MatrixWrapper(mat)\n    return mat"}
